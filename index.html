<html>

<head>
    <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
    <link rel="stylesheet" type="text/css" href="style.css" />
    <title>Bo Han</title>
    <base href="https://bhanML.github.io/index.html">
</head>

<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<h1 style="padding-left: 0.5em">Bo Han</h1><hr>
<td id="layout-menu">
    <div class="menu-item"><a href="index.html" class="current">Home</a></div>
	<div class="menu-item"><a href="news.html">News</a></div>
    <div class="menu-item"><a href="research.html">Research</a></div>
	<div class="menu-item"><a href="group.html">Research Group</a></div>
	<div class="menu-item"><a href="service.html">Professional Service</a></div>
    <!--<div class="menu-item"><a href="publication.html">Publications</a></div>-->
    <!--<div class="menu-item"><a href="teaching.html">Teaching</a></div>-->
    <div class="menu-item"><a href="codedata.html">Codes & Data</a></div>
    <!--<div class="menu-item"><a href="seminar.html">ML Seminar</a></div>-->
</td>
<td id="layout-content">

    <h1 style="margin-top: 0em">Home</h1><br>
  <!--  <p>[ <a href="#news">News</a>,
        <a href="#interest">Research Interests</a>,
        <a href="#job">Job Experience</a>,
        <a href="#edu">Education</a> ]</p>-->

    <table class="imgtable"><tr valign="top">
        <!-- <td><img src="bhan.jpg" alt="Bo Han" /></td> -->
        <td align="left">
            <p><span style="font-size: 110%"><b>Bo Han</b></span></p>
            <p>
                Assistant Professor @ <a href="https://www.comp.hkbu.edu.hk/v1/?page=home" target="_blank">Department of Computer Science</a><br>
                <a href="https://www.hkbu.edu.hk/eng/main/index.jsp" target="_blank">Hong Kong Baptist University</a><br>
			</p>
			
			<p>
                Visiting Scientist @ <a href="https://aip.riken.jp/labs/generic_tech/imperfect_inf_learn/" target="_blank">Imperfect Information Learning Team</a><br>
                <a href="http://www.riken.jp/en/" target="_blank">RIKEN</a>
                <a href="https://aip.riken.jp/" target="_blank">Center for Advanced Intelligence Project</a>
            </p>

            <p>
                <a href="https://scholar.google.com.au/citations?user=nTNjqHwAAAAJ&hl=en" target="_blank">[Google Scholar]</a>
                <a href="https://github.com/bhanML" target="_blank">[Github]</a><br>
				<!-- <a href="http://csrankings.org/#/fromyear/2019/toyear/2020/index?ai&mlmining&world" target="_blank">[CSRankings]</a> -->
				E-mail: bhanml@comp.hkbu.edu.hk & bo.han@riken.jp<br>
				I am always looking for self-motivated PhD/MPhil/Visiting/RA students. Full scholarships are available. Due to the large number of emails I receive, I cannot respond to every email individually. Thanks!
            </p>
        </td>
    </tr></table>

 <div>
        <h2><hr><a name="news"></a>News</h2>
        <ul>
		   <li><p>Aug 2020: I will co-organize ACML 2020 Workshop on <a href="https://wsl-workshop.github.io/acml20.html" target="_blank">Weakly-supervised Representation Learning</a>. </p></li>
		   <li><p>Jul 2020: I will give a talk at RIKEN AIP. </p></li>
		   <li><p>Jul 2020: I will be serving as an Area Chair of ICLR'21. </p></li>
		   <li><p>Jun 2020: I am honored to receive RGC Early CAREER Scheme 2020.</p></li>
		   <li><p>Mar 2020: I will be serving as an Area Chair of NeurIPS'20. </p></li>
		   <li><p>Mar 2020: I am honored to receive RIKEN BAIHO Award 2019. </p></li>
        </ul>
    </div>

    <div>
        <h2><hr><a name="research"></a>Research</h2>
<ul>
My research interests lie in machine learning and deep learning. My long-term goal is to develop trustworthy intelligent systems, which can learn and reason from a massive volume of complex (e.g., weakly-supervised, adversarial, and private) data (e.g, single-/multi-label, example, preference, domain, similarity, graph, and demonstration) automatically. Recently, I develop core machine learning methodology. Besides, I am actively applying our fundamental research into the healthcare domain (e.g., medical image understanding).
</ul>

<ul>
 My current research work center around four major themes (with representative works):
</ul>
<ul>
<li><p>Weakly-supervised Machine Learning: How can we train complex models robustly using weakly-supervised information? <a href="http://papers.nips.cc/paper/8072-co-teaching-robust-training-o" target="_blank">[NeurIPS'18]</a></p></li>
<li><p>Security, Privacy and Robustness in Machine Learning: How can we preserve the security, privacy and robustness in training complex models? <a href="https://arxiv.org/abs/2002.11242" target="_blank">[ICML'20]</a></p></li>
<li><p>Automated Machine Learning: How can we reason about intelligent systems without human intervention? <a href="https://arxiv.org/abs/1911.02377" target="_blank">[ICML'20]</a></p></li>
<li><p>Interdisciplinary Problems: How can we apply the above fundamental research to the healthcare domain?</p></li>
</ul>

</div>

    <div>
        <h2><hr><a name="tutorials-workshops"></a>Workshops, Tutorials and Challenges</h2>
        <ul>
		   <li><p>ACML 2020 Workshop on <a href="https://wsl-workshop.github.io/acml20.html" target="_blank">Weakly-supervised Representation Learning</a> (with Tongliang Liu, Mingming Gong, Quanming Yao, Gang Niu, Ivor W. Tsang, Masashi Sugiyama).</p></li>
		   <li><p>SDM 2020 Workshop on <a href="https://wsl-workshop.github.io/sdm20.html" target="_blank">Weakly-supervised and Unsupervised Learning</a> (with Mingming Gong, Chunyuan Li, Tongliang Liu, Quanming Yao, Gang Niu, Kun Zhang, Masashi Sugiyama).</p></li>
		   <li><p>ACML 2019 Workshop on <a href="http://www.acml-conf.org/2019/workshops/weakly-supervised/" target="_blank">Weakly-supervised Learning</a> (with Gang Niu, Quanming Yao, Giogio Patrini, Aditya Menon, Clayton Scott and Masashi Sugiyama).</p></li>
		   <li><p>ACML 2019 Tutorial on <a href="http://www.acml-conf.org/2019/tutorials/tsang-han/" target="_blank">Towards Noisy Supervision: Problems, Theories, and Algorithms</a> (with Ivor W. Tsang).</p></li>
		   <li><p>ACML 2019 Challenge on <a href="https://www.4paradigm.com/competition/autowsl2019" target="_blank">AutoML for Weakly-supervised Learning (AutoWSL)</a> (with Quanming Yao, Wei-Wei Tu, Isabelle Guyon, and Qiang Yang).</p></li>
        </ul>
    
	</div>
    <div>
        <h2><hr><a name="publications"></a>Selected Publications</h2> (* indicates advisees/co-advisees)
        <ul>
		   <li><p>Maximum Mean Discrepancy is Aware of Adversarial Attacks.<br>
		   R. Gao*, F. Liu, J. Zhang, <b>B. Han</b>, T. Liu, G. Niu, and M. Sugiyama.<br>
		   <i>arXiv preprint arXiv:2010.11415</i>, 2020, [<a href="https://arxiv.org/pdf/2010.11415.pdf" target="_blank">PDF</a>].</p></li>
		   <li><p>Geometry-aware Instance-reweighted Adversarial Training.<br>
		   J. Zhang, J. Zhu*, G. Niu, <b>B. Han</b>, M. Sugiyama, and M. Kankanhalli.<br>
		   <i>arXiv preprint arXiv:2010.01736</i>, 2020, [<a href="https://arxiv.org/pdf/2010.01736.pdf" target="_blank">PDF</a>].</p></li>
		   <li><p>Pointwise Binary Classification with Pairwise Confidence Comparisons.<br>
		   L. Feng, S. Shu, N. Lu, <b>B. Han</b>, M. Xu, G. Niu, B. An, and M. Sugiyama.<br>
		   <i>arXiv preprint arXiv:2010.01875</i>, 2020, [<a href="https://arxiv.org/pdf/2010.01875.pdf" target="_blank">PDF</a>].</p></li>
		   <li><p>Confidence Scores Make Instance-dependent Label-noise Learning Possible.<br>
		   A. Berthon, <b>B. Han</b>, G. Niu, T. Liu, and M. Sugiyama.<br>
		   <i>arXiv preprint arXiv:2001.03772</i>, 2020, [<a href="https://arxiv.org/pdf/2001.03772.pdf" target="_blank">PDF</a>].</p></li>
		   <li><p>Butterfly: One-step Approach towards Wildly Unsupervised Domain Adaptation.<br>
		   F. Liu*, J. Lu, <b>B. Han</b>, G. Niu, G. Zhang, and M. Sugiyama.<br>
		   <i>arXiv preprint arXiv:1905.07720</i>, 2019, [<a href="https://arxiv.org/pdf/1905.07720.pdf" target="_blank">PDF</a>].</p></li>
		   <li><p>Provably Consistent Partial-Label Learning.<br>
		   L. Feng, J. Lv, <b>B. Han</b>, M. Xu, G. Niu, X. Geng, B. An, and M. Sugiyama.<br>
		   In <i>Advances in Neural Information Processing Systems 33 (NeurIPS'20)</i>, [<a href="https://arxiv.org/abs/2007.08929" target="_blank">PDF</a>].</p></li>
		   <li><p>Dual T: Reducing Estimation Error for Transition Matrix in Label-noise Learning.<br>
		   Y. Yao, T. Liu, <b>B. Han</b>, M. Gong, J. Deng, G. Niu, and M. Sugiyama.<br>
		   In <i>Advances in Neural Information Processing Systems 33 (NeurIPS'20)</i>, [<a href="https://arxiv.org/abs/2006.07805" target="_blank">PDF</a>].</p></li>
		   <li><p>Parts-dependent Label Noise: Towards Instance-dependent Label Noise.<br>
		   X. Xiao, T. Liu, <b>B. Han</b>, N. Wang, M. Gong, H. Liu, G. Niu, D. Tao, and M. Sugiyama.<br>
		   In <i>Advances in Neural Information Processing Systems 33 (NeurIPS'20)</i>, [<a href="https://arxiv.org/abs/2006.07836" target="_blank">PDF</a>].</p></li>
		   <li><p>SIGUA: Forgetting May Make Learning with Noisy Labels More Robust.<br>
		   <b>B. Han</b>, G. Niu, X. Yu, Q. Yao, M. Xu, I.W. Tsang, and M. Sugiyama.<br>
		   In Proceedings of <i>37th International Conference on Machine Learning (ICML'20)</i>, [<a href="https://proceedings.icml.cc/static/paper_files/icml/2020/705-Paper.pdf" target="_blank">PDF</a>] [<a href="https://github.com/bhanML/SIGUA" target="_blank">Code</a>] [<a href="https://icml.cc/virtual/2020/poster/5866" target="_blank">Poster</a>].</p></li>
		   <li><p>Variational Imitation Learning from Diverse-quality Demonstrations.<br>
		   V. Tangkaratt, <b>B. Han</b>, M. Khan, and M. Sugiyama.<br>
		   In Proceedings of <i>37th International Conference on Machine Learning (ICML'20)</i>, [<a href="https://arxiv.org/abs/1909.06769" target="_blank">PDF</a>] [<a href="https://github.com/voot-t/vild_code" target="_blank">Code</a>] [<a href="https://icml.cc/virtual/2020/poster/5846" target="_blank">Poster</a>].</p></li>
		   <li><p>Attacks Which Do Not Kill Training Make Adversarial Learning Stronger.<br>
		   J. Zhang*, X. Xu, <b>B. Han</b>, G. Niu, L. Cui, M. Sugiyama, and M. Kankanhalli.<br>
		   In Proceedings of <i>37th International Conference on Machine Learning (ICML'20)</i>, [<a href="https://proceedings.icml.cc/static/paper_files/icml/2020/520-Paper.pdf" target="_blank">PDF</a>] [<a href="https://github.com/zjfheart/Friendly-Adversarial-Training" target="_blank">Code</a>] [<a href="https://icml.cc/virtual/2020/poster/5835" target="_blank">Poster</a>].</p></li>
		   <li><p>Searching to Exploit Memorization Effect in Learning from Noisy Labels.<br>
		   Q. Yao, H. Yang, <b>B. Han</b>, G. Niu, and J.T. Kwok.<br>
		   In Proceedings of <i>37th International Conference on Machine Learning (ICML'20)</i>, [<a href="https://proceedings.icml.cc/static/paper_files/icml/2020/3285-Paper.pdf" target="_blank">PDF</a>] [<a href="https://github.com/AutoML-4Paradigm/S2E" target="_blank">Code</a>] [<a href="https://icml.cc/virtual/2020/poster/6326" target="_blank">Poster</a>].</p></li>
		   <li><p>Learning with Multiple Complementary Labels.<br>
		   L. Feng, T. Kaneko, <b>B. Han</b>, G. Niu, B. An, and M. Sugiyama.<br>
		   In Proceedings of <i>37th International Conference on Machine Learning (ICML'20)</i>, [<a href="https://proceedings.icml.cc/static/paper_files/icml/2020/1969-Paper.pdf" target="_blank">PDF</a>] [<a href="https://icml.cc/virtual/2020/poster/6084" target="_blank">Poster</a>].</p></li>
		   <li><p>Are Anchor Points Really Indispensable in Label-noise Learning?<br>
		   X. Xiao, T. Liu, N. Wang, <b>B. Han</b>, C. Gong, G. Niu, and M. Sugiyama.<br>
		   In <i>Advances in Neural Information Processing Systems 32 (NeurIPS'19)</i>, [<a href="https://arxiv.org/abs/1906.00189" target="_blank">PDF</a>] [<a href="https://github.com/xiaoboxia/T-Revision" target="_blank">Code</a>] [<a href="https://tongliang-liu.github.io/papers/NeurIPS2019arePoster.pdf" target="_blank">Poster</a>].</p></li>
           <li><p>How does Disagreement Help Generalization against Label Corruption?<br>
		   X. Yu*, <b>B. Han</b>, J. Yao, G. Niu, I.W. Tsang, and M. Sugiyama.<br>
		   In Proceedings of <i>36th International Conference on Machine Learning (ICML'19)</i>, [<a href="http://proceedings.mlr.press/v97/yu19b.html" target="_blank">PDF</a>] [<a href="https://github.com/xingruiyu/coteaching_plus" target="_blank">Code</a>] [<a href="https://icml.cc/media/Slides/icml/2019/halla(12-16-00)-12-16-00-4938-how_does_disagr.pdf" target="_blank">Slides</a>] [<a href="papers/coteaching_plus_poster.pdf" target="_blank">Poster</a>].</p></li>
		   <li><p>Efficient Nonconvex Regularized Tensor Completion with Structure-aware Proximal Iterations.<br>
		   Q. Yao, J.T. Kwok, and <b>B. Han</b>.<br>
		   In Proceedings of <i>36th International Conference on Machine Learning (ICML'19)</i>, [<a href="http://proceedings.mlr.press/v97/yao19a.html" target="_blank">PDF</a>] [<a href="https://github.com/quanmingyao/FasTer" target="_blank">Code</a>].</p></li>
		   <li><p>Towards Robust ResNet: A Small Step but A Giant Leap.<br>
		   J. Zhang*, <b>B. Han</b>, L. Wynter, B. Low, and M. Kankanhalli.<br>
		   In Proceedings of <i>28th International Joint Conference on Artificial Intelligence (IJCAI'19)</i>, [<a href="https://www.ijcai.org/proceedings/2019/595" target="_blank">PDF</a>] [<a href="https://github.com/zjfheart/Robust-ResNet" target="_blank">Code</a>] [<a href="papers/robust_resnet_poster.pdf" target="_blank">Poster</a>].</p></li>
		   <li><p>Privacy-preserving Stochastic Gradual Learning.<br>
		    <b>B. Han</b>, I.W. Tsang, X. Xiao, L. Chen, S.-F. Fung, and C. Yu.<br>
			<i>IEEE Transactions on Knowledge and Data Engineering (TKDE)</i>, 2019, [<a href="https://ieeexplore.ieee.org/document/8949708" target="_blank">PDF</a>].</p></li>
		   <li><p>Co-teaching: Robust Training of Deep Neural Networks with Extremely Noisy Labels.<br>
		   <b>B. Han</b>, Q. Yao, X. Yu, G. Niu, M. Xu, W. Hu, I.W. Tsang, and M. Sugiyama.<br>
			In <i>Advances in Neural Information Processing Systems 31 (NeurIPS'18)</i>, [<a href="https://papers.nips.cc/paper/8072-co-teaching-robust-training-of-deep-neural-networks-with-extremely-noisy-labels" target="_blank">PDF</a>] [<a href="https://github.com/bhanML/Co-teaching" target="_blank">Code</a>] [<a href="papers/coteaching_poster.pdf" target="_blank">Poster</a>].</p></li>
		   <li><p>Masking: A New Perspective of Noisy Supervision.<br>
			<b>B. Han</b>, J. Yao, G. Niu, M. Zhou, I.W. Tsang, Y. Zhang, and M. Sugiyama.<br>
			In <i>Advances in Neural Information Processing Systems 31 (NeurIPS'18)</i>, [<a href="https://papers.nips.cc/paper/7825-masking-a-new-perspective-of-noisy-supervision" target="_blank">PDF</a>] [<a href="https://github.com/bhanML/Masking" target="_blank">Code</a>] [<a href="papers/masking_poster.pdf" target="_blank">Poster</a>].</p></li>
		    <li><p>Millionaire: A Hint-guided Approach for Crowdsourcing.<br>
			<b>B. Han</b>, Q. Yao, Y. Pan, I.W. Tsang, X. Xiao, Q. Yang, and M. Sugiyama.<br>
			<i>Machine Learning Journal (MLJ)</i>, 108(5): 831–858, 2018, [<a href="https://link.springer.com/article/10.1007/s10994-018-5766-5" target="_blank">PDF</a>] [<a href="papers/bhan_acml18.pdf" target="_blank">Slides</a>].</p></li>
		    <li><p>Stagewise Learning for Noisy k-ary Preferences.<br>
			Y. Pan, <b>B. Han</b>, and I.W. Tsang.<br>
			<i>Machine Learning Journal (MLJ)</i>, 107: 1333–1361, 2018, [<a href="https://link.springer.com/article/10.1007/s10994-018-5716-2" target="_blank">PDF</a>].</p></li>
            <li><p>Robust Plackett-Luce Model for k-ary Crowdsourced Preferences.<br>
			<b>B. Han</b>, Y. Pan, and I.W. Tsang.<br>
			<i>Machine Learning Journal (MLJ)</i>, 107(4): 675–702, 2017, [<a href="https://link.springer.com/article/10.1007/s10994-017-5674-0" target="_blank">PDF</a>].</p></li>
        </ul>
    </div>
	
	<div>
        <h2><hr><a name="biography"></a>Brief Biography</h2>
        <ul>
           Bo Han is currently an Assistant Professor of Computer Science at <a href="https://www.hkbu.edu.hk/eng/main/index.jsp" target="_blank">Hong Kong Baptist University</a>, and a Visiting Scientist at <a href="https://aip.riken.jp/" target="_blank">RIKEN Center for Advanced Intelligence Project (RIKEN AIP)</a>, hosted by <a href="http://www.ms.k.u-tokyo.ac.jp/sugi/" target="_blank">Masashi Sugiyama</a>. He was a Postdoc Fellow at RIKEN AIP (2019-2020), advised by Masashi Sugiyama. He received his Ph.D. degree in Computer Science from <a href="https://www.uts.edu.au/" target="_blank">University of Technology Sydney</a> (2015-2019), advised by <a href="https://www.uts.edu.au/staff/ivor.tsang" target="_blank">Ivor W. Tsang</a> and <a href="https://www.uts.edu.au/staff/ling.chen" target="_blank">Ling Chen</a>. During 2018-2019, he was a Research Intern with the AI Residency Program at <a href="https://aip.riken.jp/" target="_blank">RIKEN AIP</a>, working on robust deep learning projects with <a href="http://www.ms.k.u-tokyo.ac.jp/sugi/" target="_blank">Masashi Sugiyama</a>, <a href="https://niug1984.github.io/" target="_blank">Gang Niu</a> and <a href="https://mingyuanzhou.github.io/" target="_blank">Mingyuan Zhou</a>. He has served as area chairs of <a href="https://nips.cc/Conferences/2020/ProgramCommittee" target="_blank">NeurIPS'20</a> and <a href="https://iclr.cc/Conferences/2021/ProgramCommittee" target="_blank">ICLR'21</a>, and (senior) program committes of ICML, AISTATS, UAI, AAAI, IJCAI and ACML. He received the <a href="https://www.riken.jp/pr/news/2020/20200319_1/index.html" target="_blank">RIKEN BAIHO Award</a> (2019),
		   <a href="https://www.ugc.edu.hk/eng/rgc/funding_opport/ecs/" target="_blank">RGC Early CAREER Scheme</a> (2020)
		   and NSFC Young Scientists Fund (2020).
		   </p></li>
        </ul>
    </div>

    <div>
    <h2><hr><a name="sponsors"></a>Sponsors</h2>
    <img src="aip-beta.jpg" alt="RIKEN-AIP" />
    <img src="logo-ircn-beta.jpg" alt="International Research Center for Neurointelligence" />
    </div>
<script src="//t1.extreme-dm.com/f.js" id="eXF-bhan-0" async defer></script>
<!--Theme from <a href="https://www.cc.gatech.edu/~lsong/" target="_blank">Prof. Le Song</a>-->
</td>
</tr>
</table>
</body>
</html>
