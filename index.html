<html>

<head>
    <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
    <link rel="stylesheet" type="text/css" href="style.css" />
    <title>Bo Han</title>
    <base href="https://bhanML.github.io/index.html">
</head>

<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<h1 style="padding-left: 0.5em">Bo Han</h1><hr>
<td id="layout-menu">
    <div class="menu-item"><a href="index.html" class="current">Home</a></div>
	<div class="menu-item"><a href="news.html">News</a></div>
    <div class="menu-item"><a href="research.html">Research</a></div>
	<div class="menu-item"><a href="group.html">Research Group</a></div>
	<div class="menu-item"><a href="service.html">Professional Service</a></div>
    <div class="menu-item"><a href="teaching.html">Teaching</a></div>
    <div class="menu-item"><a href="codedata.html">Codes & Data</a></div>
</td>
<td id="layout-content">

    <h1 style="margin-top: 0em">Home</h1><br>
  <!--  <p>[ <a href="#news">News</a>,
        <a href="#interest">Research Interests</a>,
        <a href="#job">Job Experience</a>,
        <a href="#edu">Education</a> ]</p>-->

    <table class="imgtable"><tr valign="top">
        <!-- <td><img src="bhan.jpg" alt="Bo Han" /></td> -->
        <td align="left">
            <p><span style="font-size: 110%"><b>Bo Han</b></span></p>
            <p>
                Assistant Professor @ <a href="https://www.comp.hkbu.edu.hk/v1/?page=home" target="_blank">Department of Computer Science</a><br>
                <a href="https://www.hkbu.edu.hk/eng/main/index.jsp" target="_blank">Hong Kong Baptist University</a><br>
			</p>
			
			<p>
                BAIHO Visiting Scientist @ <a href="https://aip.riken.jp/labs/generic_tech/imperfect_inf_learn/" target="_blank">Imperfect Information Learning Team</a><br>
                <a href="http://www.riken.jp/en/" target="_blank">RIKEN</a>
                <a href="https://aip.riken.jp/" target="_blank">Center for Advanced Intelligence Project</a>
            </p>

            <p>
                <a href="https://scholar.google.com.au/citations?user=nTNjqHwAAAAJ&hl=en" target="_blank">[Google Scholar]</a>
                <a href="https://github.com/bhanML" target="_blank">[Github]</a><br>
				<!-- <a href="http://csrankings.org/#/fromyear/2019/toyear/2020/index?ai&mlmining&world" target="_blank">[CSRankings]</a> -->
				E-mail: bhanml@comp.hkbu.edu.hk & bo.han@riken.jp<br>
				I am always looking for <b>self-motivated</b> PhD/MPhil/RA/Visiting students. Please read <a href="https://bhanml.github.io/prospective_students.pdf" target="_blank">this document</a> for recruiting information. Meanwhile, I am happy to host remote research trainees. Due to the large number of emails I receive, I cannot respond to every email individually. Thanks!
            </p>
        </td>
    </tr></table>

 <div>
        <h2><hr><a name="news"></a>News</h2>
        <ul>
		   <li><p>May 2021: I am honored to receive ICLR'21 Outstanding Area Chairs. </p></li>
		   <li><p>May 2021: I will be serving as an Editorial Board Reviewer of JMLR. </p></li>
		   <li><p>Apr 2021: I will be serving as a Guest Editor of MLJ Special Issue. </p></li>
		   <li><p>Mar 2021: I will be serving as an Area Chair of NeurIPS'21. </p></li>
		   <li><p>Sep 2020: I am honored to receive ICML'20 Top Reviewers. </p></li>
		   <li><p>Jul 2020: I will be serving as an Area Chair of ICLR'21. </p></li>
		   <li><p>Jun 2020: I am honored to receive RGC Early CAREER Scheme 2020.</p></li>
		   <li><p>Mar 2020: I will be serving as an Area Chair of NeurIPS'20. </p></li>
		   <li><p>Mar 2020: I am honored to receive RIKEN BAIHO Award 2019. </p></li>
        </ul>
		See more news <a href="https://bhanml.github.io/news.html" target="_blank">here</a>.
    </div>

    <div>
        <h2><hr><a name="research"></a>Research</h2>
<ul>
My research interests lie in machine learning and deep learning. My long-term goal is to develop trustworthy intelligent systems, which can learn and reason from a massive volume of complex (e.g., weakly supervised, adversarial, private, and causal) data (e.g, single-/multi-label, example, preference, domain, similarity, graph, and demonstration) automatically. Recently, I develop core machine learning methodology. Besides, I am actively applying our fundamental research into the healthcare domain (e.g., medical image understanding and drug discovery).
</ul>

<ul>
My current research work center around four major themes (with representative works/projects; more information here):
</ul>
<ul>
<li><p>Weakly Supervised Machine Learning: How can we train complex models robustly using weakly supervised information? <a href="https://arxiv.org/pdf/2011.04406.pdf" target="_blank">[Survey]</a> <a href="http://papers.nips.cc/paper/8072-co-teaching-robust-training-o" target="_blank">[NeurIPS'18]</a> 
<a href="https://papers.nips.cc/paper/7825-masking-a-new-perspective-of-noisy-supervision" target="_blank">[NeurIPS'18]</a>
<a href="http://proceedings.mlr.press/v97/yu19b.html" target="_blank">[ICML'19]</a>
<a href="http://proceedings.mlr.press/v119/han20c.html" target="_blank">[ICML'20]</a>
<a href="https://arxiv.org/abs/2001.03772" target="_blank">[ICML'21]</a></p></li>
<li><p>Security, Privacy and Robustness in Machine Learning: How can we preserve the security, privacy and robustness in training complex models? <a href="http://proceedings.mlr.press/v119/zhang20z.html" target="_blank">[ICML'20]</a> 
<a href="https://openreview.net/forum?id=iAX0l6Cz8ub" target="_blank">[ICLR'21]</a>
<a href="https://arxiv.org/abs/2010.11415" target="_blank">[ICML'21]</a></p></li>
<li><p>Automated Machine Learning: How can we reason about intelligent systems without human intervention? <a href="http://proceedings.mlr.press/v119/yao20b.html" target="_blank">[ICML'20]</a></p></li>
<li><p>Interdisciplinary Problems: How can we apply the above fundamental research to the healthcare domain? <a href="https://research.hkbu.edu.hk/page/detail/575" target="_blank">[Project'20]</a> </p></li>
</ul>

</div>

    <div>
        <h2><hr><a name="tutorials-workshops"></a>Workshops, Tutorials, Special Issues and Challenges</h2>
        <ul>
		   <li><p>IJCAI 2021 Workshop on <a href="https://wsl-workshop.github.io/ijcai21.html" target="_blank">Weakly Supervised Representation Learning</a> (with Tongliang Liu, Quanming Yao, Mingming Gong, Chen Gong, Gang Niu, Ivor W. Tsang and Masashi Sugiyama).</p></li>
		   <li><p>IJCAI 2021 Tutorial on <a href="https://wsl-workshop.github.io/ijcai21-tutorial" target="_blank">Learning with Noisy Supervision</a> (with Tongliang Liu, Quanming Yao, Gang Niu and Masashi Sugiyama).</p></li>
		   <li><p>Guest Editor, Machine Learning Journal Special Issue on <a href="https://wsl-workshop.github.io/MLJ_WSRL_CFP.pdf" target="_blank">"Weakly Supervised Representation Learning"</a> (with Tongliang Liu, Quanming Yao, Mingming Gong, Gang Niu, Ivor W. Tsang and Masashi Sugiyama).</p></li>
		   <li><p>ACML 2020 Workshop on <a href="https://wsl-workshop.github.io/acml20.html" target="_blank">Weakly-supervised Representation Learning</a> (with Tongliang Liu, Mingming Gong, Quanming Yao, Gang Niu, Ivor W. Tsang and Masashi Sugiyama).</p></li>
		   <li><p>SDM 2020 Workshop on <a href="https://wsl-workshop.github.io/sdm20.html" target="_blank">Weakly-supervised and Unsupervised Learning</a> (with Mingming Gong, Chunyuan Li, Tongliang Liu, Quanming Yao, Gang Niu, Kun Zhang and Masashi Sugiyama).</p></li>
		   <li><p>ACML 2019 Workshop on <a href="http://www.acml-conf.org/2019/workshops/weakly-supervised/" target="_blank">Weakly-supervised Learning</a> (with Gang Niu, Quanming Yao, Giogio Patrini, Aditya Menon, Clayton Scott and Masashi Sugiyama).</p></li>
		   <li><p>ACML 2019 Tutorial on <a href="http://www.acml-conf.org/2019/tutorials/tsang-han/" target="_blank">Towards Noisy Supervision: Problems, Theories, and Algorithms</a> (with Ivor W. Tsang).</p></li>
		   <li><p>ACML 2019 Challenge on <a href="https://www.4paradigm.com/competition/autowsl2019" target="_blank">AutoML for Weakly-supervised Learning (AutoWSL)</a> (with Quanming Yao, Wei-Wei Tu, Isabelle Guyon and Qiang Yang).</p></li>
        </ul>
	</div>
    <div>
        <h2><hr><a name="publications"></a>Selected Publications</h2> (* indicates advisees/co-advisees; see the full list <a href="https://scholar.google.com.au/citations?user=nTNjqHwAAAAJ" target="_blank">here</a>)
        <ul>
		   <li><p>A Survey of Label-noise Representation Learning: Past, Present and Future.<br>
		   <b>B. Han</b>, Q. Yao, T. Liu, G. Niu, I.W. Tsang, J.T. Kwok and M. Sugiyama.<br>
		   <i>arXiv preprint arXiv:2011.04406</i>, 2020, [<a href="https://arxiv.org/pdf/2011.04406.pdf" target="_blank">PDF</a>].<br>
		   (the draft is kept updating; any comments and suggestions are welcome)</p></li>
		   <li><p>Confidence Scores Make Instance-dependent Label-noise Learning Possible.<br>
		   A. Berthon*, <b>B. Han</b>, G. Niu, T. Liu, and M. Sugiyama.<br>
		   In Proceedings of <i>38th International Conference on Machine Learning (ICML'21)</i>, [<a href="https://arxiv.org/pdf/2001.03772.pdf" target="_blank">PDF</a>] [Code] [Poster].</p></li>
		   <li><p>Maximum Mean Discrepancy is Aware of Adversarial Attacks.<br>
		   R. Gao*, F. Liu, J. Zhang, <b>B. Han</b>, T. Liu, G. Niu, and M. Sugiyama.<br>
		   In Proceedings of <i>38th International Conference on Machine Learning (ICML'21)</i>, [<a href="https://arxiv.org/pdf/2010.11415.pdf" target="_blank">PDF</a>] [Code] [Poster].</p></li>
		   <li><p>Learning Diverse-Structured Networks for Adversarial Robustness.<br>
		   X. Du*, J. Zhang, <b>B. Han</b>, T. Liu, Y. Rong, G. Niu, J. Huang and M. Sugiyama.<br>
		   In Proceedings of <i>38th International Conference on Machine Learning (ICML'21)</i>, [<a href="https://arxiv.org/pdf/2102.01886.pdf" target="_blank">PDF</a>] [Code] [Poster].</p></li>
		   <li><p>Geometry-aware Instance-reweighted Adversarial Training.<br>
		   J. Zhang, J. Zhu*, G. Niu, <b>B. Han</b>, M. Sugiyama, and M. Kankanhalli.<br>
		   In Proceedings of <i>9th International Conference on Learning Representations (ICLR'21)</i>, 2021, [<a href="https://openreview.net/pdf?id=iAX0l6Cz8ub" target="_blank">PDF</a>] [Code] [Poster].</p></li>
		   <li><p>Robust Early-learning: Hindering the Memorization of Noisy Labels.<br>
		   X. Xia, T. Liu, <b>B. Han</b>, C. Gong, N. Wang, Z. Ge, and Y. Chang.<br>
		   In Proceedings of <i>9th International Conference on Learning Representations (ICLR'21)</i>, 2021, [<a href="https://openreview.net/pdf?id=Eql5b1_hTE4" target="_blank">PDF</a>] [Code] [Poster].</p></li>
		   <li><p>Learning with Group Noise.<br>
		   Q. Wang*, J. Yao, C. Gong, T. Liu, M. Gong, H. Yang, and <b>B. Han</b>.<br>
		   In Proceedings of <i>35th AAAI Conference on Artificial Intelligence (AAAI'21)</i>, 2021, [<a href="https://arxiv.org/pdf/2103.09468.pdf" target="_blank">PDF</a>] [Code] [Poster].</p></li>
		   <li><p>Instance-Dependent Positive and Unlabeled Learning with Labeling Bias Estimation.<br>
		   C. Gong, Q. Wang*, T. Liu, <b>B. Han</b>, J. You, J. Yang, and D. Tao.<br>
		   <i>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</i>, 2021, [<a href="https://www.computer.org/csdl/journal/tp/5555/01/09361303/1rsezbEXNxS" target="_blank">PDF</a>] [Code].</p></li>
		   <li><p>Provably Consistent Partial-Label Learning.<br>
		   L. Feng, J. Lv, <b>B. Han</b>, M. Xu, G. Niu, X. Geng, B. An, and M. Sugiyama.<br>
		   In <i>Advances in Neural Information Processing Systems 33 (NeurIPS'20)</i>, [<a href="https://arxiv.org/pdf/2007.08929.pdf" target="_blank">PDF</a>] [<a href="https://lfeng1995.github.io/Codes/RCCC.rar" target="_blank">Code</a>] [Poster].</p></li>
		   <li><p>Dual T: Reducing Estimation Error for Transition Matrix in Label-noise Learning.<br>
		   Y. Yao, T. Liu, <b>B. Han</b>, M. Gong, J. Deng, G. Niu, and M. Sugiyama.<br>
		   In <i>Advances in Neural Information Processing Systems 33 (NeurIPS'20)</i>, [<a href="https://arxiv.org/pdf/2006.07805.pdf" target="_blank">PDF</a>] [Code] [Poster].</p></li>
		   <li><p>Parts-dependent Label Noise: Towards Instance-dependent Label Noise.<br>
		   X. Xiao, T. Liu, <b>B. Han</b>, N. Wang, M. Gong, H. Liu, G. Niu, D. Tao, and M. Sugiyama.<br>
		   In <i>Advances in Neural Information Processing Systems 33 (NeurIPS'20)</i>, [<a href="https://arxiv.org/pdf/2006.07836.pdf" target="_blank">PDF</a>] [Code] [Poster].</p></li>
		   <li><p>SIGUA: Forgetting May Make Learning with Noisy Labels More Robust.<br>
		   <b>B. Han</b>, G. Niu, X. Yu, Q. Yao, M. Xu, I.W. Tsang, and M. Sugiyama.<br>
		   In Proceedings of <i>37th International Conference on Machine Learning (ICML'20)</i>, [<a href="https://proceedings.mlr.press/v119/han20c/han20c.pdf" target="_blank">PDF</a>] [<a href="https://github.com/bhanML/SIGUA" target="_blank">Code</a>] [<a href="https://icml.cc/virtual/2020/poster/5866" target="_blank">Poster</a>].</p></li>
		   <li><p>Variational Imitation Learning from Diverse-quality Demonstrations.<br>
		   V. Tangkaratt, <b>B. Han</b>, M. Khan, and M. Sugiyama.<br>
		   In Proceedings of <i>37th International Conference on Machine Learning (ICML'20)</i>, [<a href="https://proceedings.mlr.press/v119/tangkaratt20a/tangkaratt20a.pdf" target="_blank">PDF</a>] [<a href="https://github.com/voot-t/vild_code" target="_blank">Code</a>] [<a href="https://icml.cc/virtual/2020/poster/5846" target="_blank">Poster</a>].</p></li>
		   <li><p>Attacks Which Do Not Kill Training Make Adversarial Learning Stronger.<br>
		   J. Zhang*, X. Xu, <b>B. Han</b>, G. Niu, L. Cui, M. Sugiyama, and M. Kankanhalli.<br>
		   In Proceedings of <i>37th International Conference on Machine Learning (ICML'20)</i>, [<a href="https://proceedings.mlr.press/v119/zhang20z/zhang20z.pdf" target="_blank">PDF</a>] [<a href="https://github.com/zjfheart/Friendly-Adversarial-Training" target="_blank">Code</a>] [<a href="https://icml.cc/virtual/2020/poster/5835" target="_blank">Poster</a>].</p></li>
		   <li><p>Searching to Exploit Memorization Effect in Learning from Noisy Labels.<br>
		   Q. Yao, H. Yang, <b>B. Han</b>, G. Niu, and J.T. Kwok.<br>
		   In Proceedings of <i>37th International Conference on Machine Learning (ICML'20)</i>, [<a href="https://proceedings.mlr.press/v119/yao20b/yao20b.pdf" target="_blank">PDF</a>] [<a href="https://github.com/AutoML-4Paradigm/S2E" target="_blank">Code</a>] [<a href="https://icml.cc/virtual/2020/poster/6326" target="_blank">Poster</a>].</p></li>
		   <li><p>Are Anchor Points Really Indispensable in Label-noise Learning?<br>
		   X. Xiao, T. Liu, N. Wang, <b>B. Han</b>, C. Gong, G. Niu, and M. Sugiyama.<br>
		   In <i>Advances in Neural Information Processing Systems 32 (NeurIPS'19)</i>, [<a href="https://proceedings.neurips.cc/paper/2019/file/9308b0d6e5898366a4a986bc33f3d3e7-Paper.pdf" target="_blank">PDF</a>] [<a href="https://github.com/xiaoboxia/T-Revision" target="_blank">Code</a>] [<a href="https://tongliang-liu.github.io/papers/NeurIPS2019arePoster.pdf" target="_blank">Poster</a>].</p></li>
           <li><p>How does Disagreement Help Generalization against Label Corruption?<br>
		   X. Yu*, <b>B. Han</b>, J. Yao, G. Niu, I.W. Tsang, and M. Sugiyama.<br>
		   In Proceedings of <i>36th International Conference on Machine Learning (ICML'19)</i>, [<a href="https://proceedings.mlr.press/v97/yu19b/yu19b.pdf" target="_blank">PDF</a>] [<a href="https://github.com/xingruiyu/coteaching_plus" target="_blank">Code</a>] [<a href="https://icml.cc/media/Slides/icml/2019/halla(12-16-00)-12-16-00-4938-how_does_disagr.pdf" target="_blank">Slides</a>] [<a href="papers/coteaching_plus_poster.pdf" target="_blank">Poster</a>].</p></li>
		   <li><p>Efficient Nonconvex Regularized Tensor Completion with Structure-aware Proximal Iterations.<br>
		   Q. Yao, J.T. Kwok, and <b>B. Han</b>.<br>
		   In Proceedings of <i>36th International Conference on Machine Learning (ICML'19)</i>, [<a href="https://proceedings.mlr.press/v97/yao19a/yao19a.pdf" target="_blank">PDF</a>] [<a href="https://github.com/quanmingyao/FasTer" target="_blank">Code</a>] [<a href="https://icml.cc/Conferences/2019/Schedule?showEvent=5191" target="_blank">Poster</a>].</p></li>
		   <li><p>Towards Robust ResNet: A Small Step but A Giant Leap.<br>
		   J. Zhang*, <b>B. Han</b>, L. Wynter, B. Low, and M. Kankanhalli.<br>
		   In Proceedings of <i>28th International Joint Conference on Artificial Intelligence (IJCAI'19)</i>, [<a href="https://www.ijcai.org/proceedings/2019/0595.pdf" target="_blank">PDF</a>] [<a href="https://github.com/zjfheart/Robust-ResNet" target="_blank">Code</a>] [<a href="papers/robust_resnet_poster.pdf" target="_blank">Poster</a>].</p></li>
		   <li><p>Privacy-preserving Stochastic Gradual Learning.<br>
		    <b>B. Han</b>, I.W. Tsang, X. Xiao, L. Chen, S.-F. Fung, and C. Yu.<br>
			<i>IEEE Transactions on Knowledge and Data Engineering (TKDE)</i>, 2019, [<a href="https://ieeexplore.ieee.org/document/8949708" target="_blank">PDF</a>].</p></li>
		   <li><p>Co-teaching: Robust Training of Deep Neural Networks with Extremely Noisy Labels.<br>
		   <b>B. Han</b>, Q. Yao, X. Yu, G. Niu, M. Xu, W. Hu, I.W. Tsang, and M. Sugiyama.<br>
			In <i>Advances in Neural Information Processing Systems 31 (NeurIPS'18)</i>, [<a href="https://papers.nips.cc/paper/2018/file/a19744e268754fb0148b017647355b7b-Paper.pdf" target="_blank">PDF</a>] [<a href="https://github.com/bhanML/Co-teaching" target="_blank">Code</a>] [<a href="papers/coteaching_poster.pdf" target="_blank">Poster</a>].</p></li>
		   <li><p>Masking: A New Perspective of Noisy Supervision.<br>
			<b>B. Han</b>, J. Yao, G. Niu, M. Zhou, I.W. Tsang, Y. Zhang, and M. Sugiyama.<br>
			In <i>Advances in Neural Information Processing Systems 31 (NeurIPS'18)</i>, [<a href="https://proceedings.neurips.cc/paper/2018/file/aee92f16efd522b9326c25cc3237ac15-Paper.pdf" target="_blank">PDF</a>] [<a href="https://github.com/bhanML/Masking" target="_blank">Code</a>] [<a href="papers/masking_poster.pdf" target="_blank">Poster</a>].</p></li>
		    <li><p>Millionaire: A Hint-guided Approach for Crowdsourcing.<br>
			<b>B. Han</b>, Q. Yao, Y. Pan, I.W. Tsang, X. Xiao, Q. Yang, and M. Sugiyama.<br>
			<i>Machine Learning Journal (MLJ)</i>, 108(5): 831–858, 2018, [<a href="https://link.springer.com/article/10.1007/s10994-018-5766-5" target="_blank">PDF</a>] [<a href="papers/bhan_acml18.pdf" target="_blank">Slides</a>].</p></li>
		    <li><p>Stagewise Learning for Noisy k-ary Preferences.<br>
			Y. Pan, <b>B. Han</b>, and I.W. Tsang.<br>
			<i>Machine Learning Journal (MLJ)</i>, 107: 1333–1361, 2018, [<a href="https://link.springer.com/article/10.1007/s10994-018-5716-2" target="_blank">PDF</a>].</p></li>
            <li><p>Robust Plackett-Luce Model for k-ary Crowdsourced Preferences.<br>
			<b>B. Han</b>, Y. Pan, and I.W. Tsang.<br>
			<i>Machine Learning Journal (MLJ)</i>, 107(4): 675–702, 2017, [<a href="https://link.springer.com/article/10.1007/s10994-017-5674-0" target="_blank">PDF</a>].</p></li>
        </ul>
    </div>
	
	<div>
        <h2><hr><a name="biography"></a>Brief Biography</h2>
        <ul>
           Bo Han is currently an Assistant Professor of Computer Science at <a href="https://www.hkbu.edu.hk/eng/main/index.jsp" target="_blank">Hong Kong Baptist University</a>, and a BAIHO Visiting Scientist at <a href="https://aip.riken.jp/" target="_blank">RIKEN Center for Advanced Intelligence Project (RIKEN AIP)</a>, hosted by <a href="http://www.ms.k.u-tokyo.ac.jp/sugi/" target="_blank">Masashi Sugiyama</a>. He was a Postdoc Fellow at RIKEN AIP (2019-2020), advised by Masashi Sugiyama. He received his Ph.D. degree in Computer Science from <a href="https://www.uts.edu.au/" target="_blank">University of Technology Sydney</a> (2015-2019), advised by <a href="https://www.uts.edu.au/staff/ivor.tsang" target="_blank">Ivor W. Tsang</a> and <a href="https://www.uts.edu.au/staff/ling.chen" target="_blank">Ling Chen</a>. During 2018-2019, he was a Research Intern with the AI Residency Program at <a href="https://aip.riken.jp/" target="_blank">RIKEN AIP</a>, working on robust deep learning projects with <a href="http://www.ms.k.u-tokyo.ac.jp/sugi/" target="_blank">Masashi Sugiyama</a>, <a href="https://niug1984.github.io/" target="_blank">Gang Niu</a> and <a href="https://mingyuanzhou.github.io/" target="_blank">Mingyuan Zhou</a>. He has served as area chairs of NeurIPS and ICLR, senior program committees of IJCAI and ACML, and program committees of ICML, AISTATS, UAI and AAAI. He has served as a guest editor of MLJ Special Issue and an editorial board reviewer of JMLR. He received the RIKEN BAIHO Award (2019), RGC Early CAREER Scheme (2020), and NSFC Young Scientists Fund (2020).
		   </p></li>
        </ul>
    </div>

    <div>
    <h2><hr><a name="sponsors"></a>Sponsors</h2>
    <img src="aip-beta.jpg" alt="RIKEN-AIP" />
    <img src="logo-ircn-beta.jpg" alt="International Research Center for Neurointelligence" />
    </div>
<script src="//t1.extreme-dm.com/f.js" id="eXF-bhan-0" async defer></script>
<!--Theme from <a href="https://www.cc.gatech.edu/~lsong/" target="_blank">Prof. Le Song</a>-->
</td>
</tr>
</table>
</body>
</html>
