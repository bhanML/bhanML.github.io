<html>

<head>
    <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
    <link rel="stylesheet" type="text/css" href="style.css" />
    <title>Bo Han</title>
    <base href="https://bhanML.github.io/codedata.html">
</head>

<body>
<h1 style="padding-left: 0.5em">Bo Han</h1><hr>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
    <div class="menu-item"><a href="index.html" class="current">Home</a></div>
	<div class="menu-item"><a href="news.html">News</a></div>
    <div class="menu-item"><a href="research.html">Research</a></div>
	<div class="menu-item"><a href="group.html">Research Group</a></div>
	<div class="menu-item"><a href="service.html">Professional Service</a></div>
    <div class="menu-item"><a href="teaching.html">Teaching</a></div>
    <div class="menu-item"><a href="codedata.html">Codes & Data</a></div>
</td>
<td id="layout-content">

    <div>
        <h2><hr><a name="codesdata"></a>Codes and Data (Reproducible Research)</h2>
            <ul>
            <li><p>
                Masking: A New Perspective of Noisy Supervision,
                [<a href="https://github.com/bhanML/Masking" target="_blank">code</a>].<br>
            </p></li>
            <li><p>
                Co-teaching: Robust Training of Deep Neural Networks with Extremely Noisy Labels,
                [<a href="https://github.com/bhanML/Co-teaching" target="_blank">code</a>].<br>
            </p></li>
			<li><p>
                How does Disagreement Help Generalization against Label Corruption,
                [<a href="https://github.com/xingruiyu/coteaching_plus" target="_blank">code</a>].<br>
            </p></li>
			<li><p>
                Efficient Nonconvex Regularized Tensor Completion with Structure-aware Proximal Iterations,
                [<a href="https://github.com/quanmingyao/FasTer" target="_blank">code</a>].<br>
            </p></li>
			<li><p>
                Towards Robust ResNet: A Small Step but A Giant Leap,
                [<a href="https://github.com/zjfheart/Robust-ResNet" target="_blank">code</a>].<br>
            </p></li>
			<li><p>
                Are Anchor Points Really Indispensable in Label-noise Learning,
                [<a href="https://github.com/xiaoboxia/T-Revision" target="_blank">code</a>].<br>
            </p></li>
		    <li><p>SIGUA: Forgetting May Make Learning with Noisy Labels More Robust,
		         [<a href="https://github.com/bhanML/SIGUA" target="_blank">code</a>].<br>
		    </p></li>
		    <li><p>Variational Imitation Learning from Diverse-quality Demonstrations,
		         [<a href="https://github.com/voot-t/vild_code" target="_blank">code</a>].<br>
            </p></li>
		    <li><p>Attacks Which Do Not Kill Training Make Adversarial Learning Stronger,
		         [<a href="https://github.com/zjfheart/Friendly-Adversarial-Training" target="_blank">code</a>].<br>
		    </p></li>
		    <li><p>Searching to Exploit Memorization Effect in Learning from Noisy Labels, 
		         [<a href="https://github.com/AutoML-4Paradigm/S2E" target="_blank">code</a>].<br>
		    </p></li>
		    <li><p>Provably Consistent Partial-Label Learning, [<a href="https://lfeng-ntu.github.io/Codes/RCCC.rar" target="_blank">code</a>].</p></li>
		    <li><p>Dual T: Reducing Estimation Error for Transition Matrix in Label-noise Learning, [code].</p></li>
		    <li><p>Part-dependent Label Noise: Towards Instance-dependent Label Noise, 
		         [<a href="https://github.com/xiaoboxia/Part-dependent-label-noise" target="_blank">code</a>].<br>
		    </p></li>
			<li><p>Learning with Group Noise, [code].</p></li>
			<li><p>Geometry-aware Instance-reweighted Adversarial Training,
			     [<a href="https://github.com/zjfheart/Geometry-aware-Instance-reweighted-Adversarial-Training" target="_blank">code</a>].<br>
			</p></li>
		    <li><p>Robust Early-learning: Hindering the Memorization of Noisy Labels,
			     [<a href="https://github.com/xiaoboxia/CDR" target="_blank">code</a>].<br>
			</p></li>
		    <li><p>Confidence Scores Make Instance-dependent Label-noise Learning Possible, 
			     [<a href="https://github.com/antoninbrthn/CSIDN" target="_blank">code</a>].<br>
            </p></li>
		    <li><p>Maximum Mean Discrepancy is Aware of Adversarial Attacks, 
			     [<a href="https://github.com/Sjtubrian/SAMMD" target="_blank">code</a>].<br>
            </p></li>
		    <li><p>Learning Diverse-Structured Networks for Adversarial Robustness, 
			     [<a href="https://github.com/d12306/dsnet" target="_blank">code</a>].<br>
			</p></li>
           </ul>
    </div>
</td>
</tr>
</table>
</body>
</html> 