<html>

<head>
    <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
    <link rel="stylesheet" type="text/css" href="style.css" />
    <title>Bo Han</title>
    <base href="https://bhanML.github.io/codedata.html">
</head>

<body>
<h1 style="padding-left: 0.5em">Bo Han</h1><hr>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
    <div class="menu-item"><a href="index.html" class="current">Home</a></div>
	<div class="menu-item"><a href="news.html">News</a></div>
    <div class="menu-item"><a href="research.html">Research</a></div>
	<div class="menu-item"><a href="group.html">Research Group</a></div>
	<div class="menu-item"><a href="service.html">Professional Service</a></div>
    <div class="menu-item"><a href="teaching.html">Teaching</a></div>
    <div class="menu-item"><a href="codedata.html">Codes & Data</a></div>
</td>
<td id="layout-content">

    <div>
        <h2><a name="codesdata"></a>Codes and Data from TML Group (Reproducible Research)</h2>
            <ul>
            <li><p>
                Masking: A New Perspective of Noisy Supervision,
                [<a href="https://github.com/bhanML/Masking" target="_blank">code</a>].<br>
            </p></li>
            <li><p>
                Co-teaching: Robust Training of Deep Neural Networks with Extremely Noisy Labels,
                [<a href="https://github.com/bhanML/Co-teaching" target="_blank">code</a>].<br>
            </p></li>
			<li><p>
                How does Disagreement Help Generalization against Label Corruption,
                [<a href="https://github.com/xingruiyu/coteaching_plus" target="_blank">code</a>].<br>
            </p></li>
			<li><p>
                Efficient Nonconvex Regularized Tensor Completion with Structure-aware Proximal Iterations,
                [<a href="https://github.com/quanmingyao/FasTer" target="_blank">code</a>].<br>
            </p></li>
			<li><p>
                Towards Robust ResNet: A Small Step but A Giant Leap,
                [<a href="https://github.com/zjfheart/Robust-ResNet" target="_blank">code</a>].<br>
            </p></li>
			<li><p>
                Are Anchor Points Really Indispensable in Label-noise Learning,
                [<a href="https://github.com/xiaoboxia/T-Revision" target="_blank">code</a>].<br>
            </p></li>
		    <li><p>SIGUA: Forgetting May Make Learning with Noisy Labels More Robust,
		         [<a href="https://github.com/bhanML/SIGUA" target="_blank">code</a>].<br>
		    </p></li>
		    <li><p>Variational Imitation Learning from Diverse-quality Demonstrations,
		         [<a href="https://github.com/voot-t/vild_code" target="_blank">code</a>].<br>
            </p></li>
		    <li><p>Attacks Which Do Not Kill Training Make Adversarial Learning Stronger,
		         [<a href="https://github.com/zjfheart/Friendly-Adversarial-Training" target="_blank">code</a>].<br>
		    </p></li>
		    <li><p>Searching to Exploit Memorization Effect in Learning from Noisy Labels, 
		         [<a href="https://github.com/AutoML-4Paradigm/S2E" target="_blank">code</a>].<br>
		    </p></li>
			<li><p>Learning with Multiple Complementary Labels,
		         [<a href="https://lfeng-ntu.github.io/Codes/LMCL.rar" target="_blank">code</a>].<br>
		    </p></li>
		    <li><p>Provably Consistent Partial-Label Learning, 
			     [<a href="https://lfeng-ntu.github.io/Codes/RCCC.rar" target="_blank">code</a>].
			</p></li>
		    <li><p>Dual T: Reducing Estimation Error for Transition Matrix in Label-noise Learning, [<a href="https://github.com/a5507203/dual-T-Estimator" target="_blank">code</a>].</p></li>
		    <li><p>Part-dependent Label Noise: Towards Instance-dependent Label Noise, 
		         [<a href="https://github.com/xiaoboxia/Part-dependent-label-noise" target="_blank">code</a>].<br>
		    </p></li>
			<li><p>Learning with Group Noise,
			      [<a href="https://github.com/QizhouWang/Max-Matching" target="_blank">code</a>].<br>
			</p></li>
			<li><p>Tackling Instance-Dependent Label Noise via a Universal Probabilistic Model,
			      [<a href="https://github.com/QizhouWang/instance-dependent-label-noise" target="_blank">code</a>].<br>
			</p></li>
			<li><p>Geometry-aware Instance-reweighted Adversarial Training,
			     [<a href="https://github.com/zjfheart/Geometry-aware-Instance-reweighted-Adversarial-Training" target="_blank">code</a>].<br>
			</p></li>
		    <li><p>Robust Early-learning: Hindering the Memorization of Noisy Labels,
			     [<a href="https://github.com/xiaoboxia/CDR" target="_blank">code</a>].<br>
			</p></li>
		    <li><p>Confidence Scores Make Instance-dependent Label-noise Learning Possible, 
			     [<a href="https://github.com/antoninbrthn/CSIDN" target="_blank">code</a>].<br>
            </p></li>
		    <li><p>Maximum Mean Discrepancy is Aware of Adversarial Attacks, 
			     [<a href="https://github.com/Sjtubrian/SAMMD" target="_blank">code</a>].<br>
            </p></li>
		    <li><p>Learning Diverse-Structured Networks for Adversarial Robustness, 
			     [<a href="https://github.com/d12306/dsnet" target="_blank">code</a>].<br>
			</p></li>
			<li><p>Class2Simi: A Noise Reduction Perspective on Learning with Noisy Labels, 
			     [<a href="https://github.com/scifancier/Class2Simi" target="_blank">code</a>].<br>
			</p></li>
			<li><p>Provably End-to-end Label-noise Learning without Anchor Points, 
			     [<a href="https://github.com/xuefeng-li1/Provably-end-to-end-label-noise-learning-without-anchor-points" target="_blank">code</a>].<br>
			</p></li>
			<li><p>Probabilistic Margins for Instance Reweighting in Adversarial Training, 
			     [<a href="https://github.com/QizhouWang/MAIL" target="_blank">code</a>].<br>
			</p></li>
			<li><p>TOHAN: A One-step Approach towards Few-shot Hypothesis Adaptation,
			     [<a href="https://github.com/Haoang97/TOHAN" target="_blank">code</a>].<br>
			</p></li>
			<li><p>Instance-dependent Label-noise Learning under a Structural Causal Model, 
			     [<a href="https://github.com/a5507203/IDLN" target="_blank">code</a>].<br>
			</p></li>
			<li><p>Adversarial Robustness Through the Lens of Causality, [<a href="https://github.com/YonggangZhangUSTC/CausalAdv" target="_blank">code</a>].<br>
			</p></li>
			<li><p>Exploiting Class Activation Value for Partial-Label Learning, [code].<br>
			</p></li>
			<li><p>Understanding and Improving Graph Injection Attack by Promoting Unnoticeability, [<a href="https://github.com/LFhase/GIA-HAO" target="_blank">code</a>].<br>
			</p></li>
			<li><p>Meta Discovery: Learning to Discover Novel Classes given Very Limited Data, [code].<br>
			</p></li>
			<li><p>Reliable Adversarial Distillation with Unreliable Teachers, [<a href="https://github.com/ZFancy/IAD" target="_blank">code</a>].<br>
			</p></li>
			<li><p>Rethinking Class-Prior Estimation for Positive-Unlabeled Learning, [code].<br>
			</p></li>
			<li><p>Sample Selection with Uncertainty of Losses for Learning with Noisy Labels, [code].<br>
			</p></li>
           </ul>
    </div>
	
	<div>
    <h2><a name="codesdata"></a>Codes and Data from RIKEN Team (Reproducible Research)</h2>
	<ul>At Imperfect Information Learning Team, Center for Advanced Intelligence Project (AIP), RIKEN, we are developing reliable and robust machine learning methods/algorithms that can cope with various factors such as weak supervision, noisy supervision, and adversarial attacks. Please check <a href="https://wsl-workshop.github.io/software.html" target="_blank">this page</a>, which hosts our program codes used in our published papers.</ul>
    </div>
	
</td>
</tr>
</table>
</body>
</html> 