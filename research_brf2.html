<html>

<head>
    <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
    <link rel="stylesheet" type="text/css" href="style.css" />
    <title>Bo Han</title>
    <base href="https://bhanML.github.io/research.html">
</head>

<body>
<h1 style="padding-left: 0.5em">Bo Han</h1><hr>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
    <div class="menu-item"><a href="index.html">Home</a></div>
	<div class="menu-item"><a href="news.html">News</a></div>
    <div class="menu-item"><a href="research.html">Research</a></div>
	<div class="menu-item"><a href="group.html">Research Group</a></div>
	<div class="menu-item"><a href="service.html">Professional Service</a></div>
    <div class="menu-item"><a href="teaching.html">Teaching</a></div>
    <div class="menu-item"><a href="codedata.html">Codes & Data</a></div>
	<div class="menu-item"><a href="awards.html">Awards & Honors</a></div>
</td>
<td id="layout-content">

<div>
        <h2><a name="research_ecs"></a>GDST Basic Research Fund</h2> (PI: Dr. Bo Han, Department of Computer Science, Hong Kong Baptist University)<br><br>

<ul>
<h3>Project Award Information</h3>
<li><p>Award Number: <a href="https://gdstc.gd.gov.cn/zwgk_n/tzgg/content/post_4177617.html" target="_blank">GDST BRF 2024A1515012399</a></p></li>
<li><p>Title: Trustworthy Graph Representation Learning under Out-of-distribution Data</p></li>
<li><p>Principal Investigator (PI): Dr. Bo Han, Department of Computer Science, Hong Kong Baptist University</p></li>
</ul>

<ul>
<h3>Project Summary</h3>
This project aims to explore new directions in trustworthy graph representation learning (TGRL) under out-of-distribution data, with applications to foundation models (e.g., ChatGPT), drug discovery, and social networks. It is motivated by the fact that: most of the existing approaches in graph representation learning implicitly assume that the training and test graph data are independent and identically distributed (i.e., i.i.d.). However, such an assumption can rarely hold in real-world applications. Instead, several recent studies have shown that the performance of graph representation learning methods can dramatically decrease when encountering out-of-distribution (OOD) data. To break such limitations, this project proposes to address the above challenge by four critical tasks. The main idea is to integrate trustworthy learning with graph representation learning, which can prevent performance degradation under OOD data. Specifically, from the perspective of invariance, Task 1 will study the fundamental theories and assumptions required for learning causally invariant graph representations, which are generalizable to OOD graph data. From the perspective of robustness, Task 2 will study how to make the adaptation for graph OOD detection, which is based on the reprogramming property of deep learning. From the perspective of interpretability, Task 3 will study how to provide explanations for predictions on OOD graph data. From the perspective of expressiveness, Task 4 will study the expressive graph neural architectures that have better OOD generalization ability. More importantly, we hope to apply the proposed TGRL algorithms to foundation models, drug discovery, and social networks.
</ul>

<ul>
<h3>Research Publications</h3>
<li><p>combating bilateral edge noise for robust link prediction (<a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/435986a8cc3e0667648df5d1c2d55c83-Paper-Conference.pdf" target="_blank">NeurIPS'23</a>)</p></li>
<li><p>understanding and improving feature learning for out-of-distribution generalization (<a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/d73d5645ddbb9ada6c862116435574f6-Paper-Conference.pdf" target="_blank">NeurIPS'23</a>)</p></li>
<li><p>invariant graph learning via environment augmentation (<a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/e21a7b668ce3ea2c9c964c52d1c9f161-Supplemental-Conference.pdf" target="_blank">NeurIPS'23</a>)</p></li>
<li><p>learning adaptive propagation for graph neural network based knowledge graph (<a href="https://dl.acm.org/doi/pdf/10.1145/3580305.3599404" target="_blank">KDD'23</a>)</p></li>
<li><p>what if the input is expanded in OOD detection (<a href="https://openreview.net/pdf?id=XfPiFRnuAS" target="_blank">NeurIPS'24</a>)</p></li>
<li><p>mitigating label noise on graphs via topological sample selection (<a href="https://arxiv.org/pdf/2403.01942" target="_blank">ICML'24</a>)</p></li>
<li><p>how interpretable are interpretable graph neural networks (<a href="https://arxiv.org/pdf/2406.07955" target="_blank">ICML'24</a>)</p></li>
<li><p>one-shot subgraph reasoning on large-scale knowledge graphs (<a href="https://arxiv.org/pdf/2403.10231" target="_blank">ICLR'24</a>)</p></li>
<li><p>on the learnability of out-of-distribution detection (<a href="https://jmlr.org/papers/volume25/23-1257/23-1257.pdf" target="_blank">JMLR'24</a>)</p></li>
<li><p>improving invariant learning by exploring variant parameters (<a href="https://link.springer.com/article/10.1007/s11263-024-02075-x" target="_blank">IJCV'24</a>)</p></li>
<li><p>counterfactual-based susceptibility risk framework for open-set domain adaptation (<a href="https://openreview.net/pdf?id=uocLJOnKBv" target="_blank">ICML'25</a>)</p></li>
<li><p>out-of-model generalization (<a href="https://openreview.net/pdf?id=LuVulfPgZN" target="_blank">ICLR'25</a>)</p></li>
<li><p>Wasserstein distribution-agnostic outlier exposure (<a href="https://www.computer.org/csdl/journal/tp/5555/01/10844561/23zUi92f3os" target="_blank">TPAMI'25</a>)</p></li>
</ul>

<ul>
<h3>Software</h3>
<li><p>combating bilateral edge noise for robust link prediction, [<a href="https://github.com/tmlr-group/RGIB" target="_blank">code</a>]</p></li>
<li><p>understanding and improving feature learning for out-of-distribution generalization, [<a href="https://github.com/tmlr-group/FeAT" target="_blank">code</a>]</p></li>
<li><p>invariant graph learning via environment augmentation, [<a href="https://github.com/tmlr-group/GALA" target="_blank">code</a>]</p></li>
<li><p>learning adaptive propagation for graph neural network based knowledge graph, [<a href="https://github.com/LARS-research/AdaProp" target="_blank">code</a>]</p></li>
<li><p>what if the input is expanded in OOD detection, [<a href="https://github.com/tmlr-group/CoVer" target="_blank">code</a>]</p></li>
<li><p>mitigating label noise on graphs via topological sample selection, [<a href="https://github.com/tmllab/2024_ICML_TSS" target="_blank">code</a>]</p></li>
<li><p>how interpretable are interpretable graph neural networks, [<a href="https://github.com/tmlr-group/GMT" target="_blank">code</a>]</p></li>
<li><p>one-shot subgraph reasoning on large-scale knowledge graphs, [<a href="https://github.com/tmlr-group/one-shot-subgraph" target="_blank">code</a>]</p></li>
<li><p>improving invariant learning by exploring variant parameters, [<a href="https://github.com/tmllab/EVIL" target="_blank">code</a>]</p></li>
<li><p>counterfactual-based susceptibility risk framework for open-set domain adaptation, [<a href="https://github.com/ZHOURui6025/COSDA-master" target="_blank">code</a>]</p></li>
<li><p>out-of-model generalization, [code]</p></li>
<li><p>Wasserstein distribution-agnostic outlier exposure, [<a href="https://github.com/tmlr-group/W-DOE" target="_blank">code</a>]</p></li>
</ul>

<ul>
<h3>Collaborators</h3>
<li><p> University: University of Wisconsin-Madison, The University of Sydney, The University of Melbourne, University of Technology Sydney, MBZUAI, Hong Kong University of Science and Technology, The Chinese University of Hong Kong, Tsinghua University, Shanghai Jiao Tong University, Wuhan University, Ocean University of China</p></li>
<li><p> Institute: RIKEN Center for Advanced Intelligence Project, Shanghai AI Laboratory</p></li>
<li><p>	Industry: Alibaba Research, Tencent AI Lab, JD Explore Academy</p></li>
</ul>

<ul>
<h3>Acknowlewdgement</h3>
This material is based upon work supported by the GDST under Grant No. 2024A1515012399. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the GDST.
</ul>

</div>

</td>
</tr>
</table>
</body>
</html>
