<html>

<head>
    <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
    <link rel="stylesheet" type="text/css" href="style.css" />
    <title>Bo Han</title>
    <base href="https://bhanML.github.io/research.html">
</head>

<body>
<h1 style="padding-left: 0.5em">Bo Han</h1><hr>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
    <div class="menu-item"><a href="index.html">Home</a></div>
	<div class="menu-item"><a href="news.html">News</a></div>
    <div class="menu-item"><a href="research.html">Research</a></div>
	<div class="menu-item"><a href="group.html">Research Group</a></div>
	<div class="menu-item"><a href="service.html">Professional Service</a></div>
    <div class="menu-item"><a href="teaching.html">Teaching</a></div>
    <div class="menu-item"><a href="codedata.html">Codes & Data</a></div>
	<div class="menu-item"><a href="awards.html">Awards & Honors</a></div>
</td>
<td id="layout-content">

<div>
        <h2><a name="research_ecs"></a>RIKEN BAIHO Award</h2> (PI: Dr. Bo Han, Department of Computer Science, Hong Kong Baptist University & RIKEN Center for Advanced Intelligence Project)<br><br>

<ul>
<h3>Project Award Information</h3>
<li><p>Title: Development of Robust Deep Learning Technologies for Heavily Noisy Data</p></li>
<li><p>Principal Investigator (PI): Dr. Bo Han, Department of Computer Science, Hong Kong Baptist University & RIKEN Center for Advanced Intelligence Project</p></li>
</ul>

<ul>
<h3>Project Summary</h3>
This project aims to develop of robust deep learning technologies for heavily noisy data.
</ul>

<ul>
<h3>Research Publications</h3>
<li><p>a new perspective of noisy supervision (<a href="https://proceedings.neurips.cc/paper/2018/file/aee92f16efd522b9326c25cc3237ac15-Paper.pdf" target="_blank">NeurIPS'18</a>)</p></li>
<li><p>robust training of deep neural networks with extremely noisy labels (<a href="https://proceedings.neurips.cc/paper_files/paper/2018/file/a19744e268754fb0148b017647355b7b-Paper.pdf" target="_blank">NeurIPS'18</a>, <a href="https://www.paperdigest.org/2022/05/most-influential-nips-papers-2022-05/" target="_blank"><font color="red">Most Influential Paper</font></a>)</p></li>
<li><p>disagreement helps generalization against label corruption (<a href="https://proceedings.mlr.press/v97/yu19b/yu19b.pdf" target="_blank">ICML'19</a>, <font color="red">Long Oral</font>)</p></li>
<li><p>forgetting may make learning with noisy labels more robust (<a href="https://proceedings.mlr.press/v119/han20c/han20c.pdf" target="_blank">ICML'20</a>)</p></li>
<li><p>variational imitation learning with diverse-quality demonstrations (<a href="https://proceedings.mlr.press/v119/tangkaratt20a/tangkaratt20a.pdf" target="_blank">ICML'20</a>)</p></li>
<li><p>friendly adversarial training (<a href="https://proceedings.mlr.press/v119/zhang20z/zhang20z.pdf" target="_blank">ICML'20</a>)</p></li>
<li><p>confidence scores make instance-dependent label-noise learning possible (<a href="http://proceedings.mlr.press/v139/berthon21a/berthon21a.pdf" target="_blank">ICML'21</a>, <font color="red">Long Oral</font>)</p></li>
<li><p>geometry-aware instance-reweighted adversarial training (<a href="https://openreview.net/pdf?id=iAX0l6Cz8ub" target="_blank">ICLR'21</a>, <font color="red">Oral</font>)</p></li>
<li><p>adversarial training with complementary labels (<a href="https://proceedings.neurips.cc/paper_files/paper/2022/file/959f70ee50044bed305e48e3484005a7-Paper-Conference.pdf" target="_blank">NeurIPS'22</a>, <font color="red">Spotlight</font>)</p></li>
<li><p>learning from noisy pairwise similarity and unlabeled data (<a href="https://www.jmlr.org/papers/volume23/21-0946/21-0946.pdf" target="_blank">JMLR'22</a>)</p></li>
<li><p>diversified outlier exposure for out-of-distribution detection (<a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/46d943bc6a15a57c923829efc0db7c7a-Paper-Conference.pdf" target="_blank">NeurIPS'23</a>)</p></li>
<li><p>towards effective evaluations and comparison for LLM unlearning methods (<a href="https://openreview.net/pdf?id=wUtCieKuQU" target="_blank">ICLR'25</a>)</p></li>
</ul>

<ul>
<h3>Software</h3>
<li><p>a new perspective of noisy supervision, [<a href="https://github.com/bhanML/Masking" target="_blank">code</a>]</p></li>
<li><p>robust training of deep neural networks with extremely noisy labels, [<a href="https://github.com/bhanML/Co-teaching" target="_blank">code</a>]</p></li>
<li><p>disagreement helps generalization against label corruption, [<a href="https://github.com/xingruiyu/coteaching_plus" target="_blank">code</a>]</p></li>
<li><p>forgetting may make learning with noisy labels more robust, [<a href="https://github.com/bhanML/SIGUA" target="_blank">code</a>]</p></li>
<li><p>variational imitation learning with diverse-quality demonstrations, [<a href="https://github.com/voot-t/vild_code" target="_blank">code</a>]</p></li>
<li><p>friendly adversarial training, [<a href="https://github.com/zjfheart/Friendly-Adversarial-Training" target="_blank">code</a>]</p></li>
<li><p>confidence scores make instance-dependent label-noise learning possible, [<a href="https://github.com/tmlr-group/CSIDN" target="_blank">code</a>]</p></li>
<li><p>geometry-aware instance-reweighted adversarial training, [<a href="https://github.com/tmlr-group/Geometry-aware-Instance-reweighted-Adversarial-Training" target="_blank">code</a>]</p></li>
<li><p>adversarial training with complementary labels, [<a href="https://github.com/tmlr-group/ATCL" target="_blank">code</a>]</p></li>
<li><p>learning from noisy pairwise similarity and unlabeled data, [<a href="https://github.com/scifancier/Learning-from-Noisy-Pairwise-Similarity-and-Unlabeled-Data" target="_blank">code</a>]</p></li>
<li><p>diversified outlier exposure for out-of-distribution detection, [<a href="https://github.com/tmlr-group/DivOE" target="_blank">code</a>]</p></li>
<li><p>towards effective evaluations and comparison for LLM unlearning methods, [<a href="https://github.com/tmlr-group/Unlearning-with-Control" target="_blank">code</a>]</p></li>
</ul>

<ul>
<h3>Collaborators</h3>
<li><p> Institute: RIKEN Center for Advanced Intelligence Project</p></li>
</ul>

<ul>
<h3>Acknowlewdgement</h3>
This material is based upon work supported by the RIKEN AIP. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the RIKEN AIP.
</ul>

</div>

</td>
</tr>
</table>
</body>
</html>
