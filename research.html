<html>

<head>
    <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
    <link rel="stylesheet" type="text/css" href="style.css" />
    <title>Bo Han</title>
    <base href="https://bhanML.github.io/research.html">
</head>

<body>
<h1 style="padding-left: 0.5em">Bo Han</h1><hr>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
    <div class="menu-item"><a href="index.html">Home</a></div>
	<div class="menu-item"><a href="news.html">News</a></div>
    <div class="menu-item"><a href="research.html" class="current">Research</a></div>
	<div class="menu-item"><a href="group.html">Research Group</a></div>
	<div class="menu-item"><a href="service.html">Professional Service</a></div>
    <div class="menu-item"><a href="teaching.html">Teaching</a></div>
    <div class="menu-item"><a href="codedata.html">Codes & Data</a></div>
	<div class="menu-item"><a href="awards.html">Awards & Honors</a></div>
</td>
<td id="layout-content">

<div>
        <h2><a name="research"></a>Research (Selected Topics)</h2> (* Link to: <a href="https://bhanml.github.io/research_ecs.html" target="_blank">RGC Early CAREER Scheme website</a>)<br><br>

<ul>
<h3>Foundation Models and Causal Representation Learning</h3>
Foundation Models (FMs) have shown impressive ability in real-life scenarios, including general problem-solving and multi-modal data processing. The success of FMs can be credited to the large amounts of corpus. As such, harmful and offensive content will inevitably be included. Additionally, preventing FMs from generating harmful information is still challenging. Compared to previous methods, FMs are able to process multi-modal data, such as images and texts. Due to the various kinds of data sources and types, noise and semantic inconsistency inevitably exist in the multi-modal data. On the other hand, causality offers a rigorous way to investigate data-generating processes behind data. It is still an open problem how causality and foundation models can reliably benefit each other. Here are some potential frontiers: Leveraging the capabilities of FMs to enhance causality in representation abstraction, structure identification, treatment effect estimation, and counterfactual predictions. Meanwhile, utilizing rigorous methods like causal abstraction and identification to investigate the inner mechanisms of FMs, including the reasoning ability, in-context learning ability, and trustworthy properties like explainability, fairness, and safety.
</ul>

<ul>
Relevant Work/Publications:
</ul>
<ul>
<li><p>trustworthy machine learning from data to models (<a href="papers/monograph_sec_tmlr.pdf" target="_blank">Monograph</a>)</p></li>
<li><p>robust LLMs reasoning in chain-of-thought prompting with noisy rationales (<a href="https://papers.nips.cc/paper_files/paper/2024/file/dfaa29ed28dfa175bcc5e2a54aa199f8-Paper-Conference.pdf" target="_blank">NeurIPS'24</a>)</p></li>
<li><p>active reasoning benchmark (<a href="https://openreview.net/pdf?id=LCaTpVuvpj" target="_blank">ICML'25</a>)</p></li>
<li><p>multi-agent reasoning through incomplete information and consensus (<a href="https://openreview.net/pdf?id=RQwexjUCxm" target="_blank">ICML'25</a>)</p></li>
<li><p>trustworthy machine unlearning for large language models (<a href="https://openreview.net/pdf?id=huo8MqVH6t" target="_blank">ICLR'25</a>, <a href="https://openreview.net/pdf?id=wUtCieKuQU" target="_blank">ICLR'25</a>, <a href="https://openreview.net/pdf?id=EAjhGr1Oeo" target="_blank">ICML'25</a>, <a href="https://openreview.net/pdf?id=mGOugCZlAq" target="_blank">ICML'25</a>, <a href="https://openreview.net/pdf?id=tcK4PV3VN4" target="_blank">ICML'25</a>)</p></li>
<li><p>out-of-distribution detection with vision-language models and large language models (<a href="https://openreview.net/pdf?id=xUO1HXz4an" target="_blank">ICLR'24</a>, <a href="https://openreview.net/pdf?id=nanyAujl6e" target="_blank">ICLR'24</a>, <a href="https://raw.githubusercontent.com/mlresearch/v235/main/assets/cao24d/cao24d.pdf" target="_blank">ICML'24</a>, <a href="https://papers.nips.cc/paper_files/paper/2024/file/666e5e1df2d04dbe2b545ea3a3e3f7d3-Paper-Conference.pdf" target="_blank">NeurIPS'24</a>)</p></li>
<li><p>detecting AI-generated texts, images and videos (<a href="https://openreview.net/pdf?id=3fEKavFsnv" target="_blank">ICLR'24</a>, <a href="https://openreview.net/pdf?id=BUkXhMb7ml" target="_blank">NeurIPS'25</a>, <a href="https://openreview.net/pdf?id=27xTIAFbc6" target="_blank">NeurIPS'25</a>, <a href="https://openreview.net/pdf?id=5SqbLPaBww" target="_blank">NeurIPS'25</a>, <a href="https://openreview.net/pdf?id=HiBoJLCyEo" target="_blank">NeurIPS'25</a>)</p></li>
<li><p>designing and understanding jailbreak prompts for large language models (<a href="https://arxiv.org/pdf/2311.03191" target="_blank">arXiv'24</a>, <a href="https://openreview.net/pdf?id=asR9FVd4eL" target="_blank">ICLR'25</a>)</p></li>
<li><p>interpretability through the lens of semantic dependency (<a href="https://openreview.net/pdf?id=7v2loOdcLH" target="_blank">ICML'25</a>)</p></li>
<li><p>noise correction and golden noise with diffusion models (<a href="https://openreview.net/pdf?id=6O3Q6AFUTu" target="_blank">ICLR'24</a>, <a href="https://arxiv.org/pdf/2411.09502" target="_blank">ICCV'25</a>)</p></li>
<li><p>evaluation dataset of vision-language models (<a href="https://papers.nips.cc/paper_files/paper/2024/file/dd59fad18638714e6c447a3b7b9c4160-Paper-Conference.pdf" target="_blank">NeurIPS'24</a>)</p></li>
<li><p>open-world vision-language models and multimodal LLMs (<a href="https://openreview.net/pdf?id=iylpeTI0Ql" target="_blank">ICLR'25</a>, <a href="https://openreview.net/pdf?id=NQSWkmjODD" target="_blank">NeurIPS'25</a>, <a href="https://link.springer.com/article/10.1007/s10994-025-06742-z" target="_blank">MLJ'25</a>)</p></li>
<li><p>discovery of the hidden world with large language models (<a href="https://openreview.net/pdf?id=w50ICQC6QJ" target="_blank">NeurIPS'24</a>)</p></li>
<li><p>causal reasoning in large language models (<a href="https://papers.nips.cc/paper_files/paper/2024/file/af2bb2b2280d36f8842e440b4e275152-Paper-Conference.pdf" target="_blank">NeurIPS'24</a>, <a href="https://arxiv.org/pdf/2412.15314" target="_blank">AAAI'25</a>)</p></li>
<li><p>robustness through the lens of causality (<a href="https://proceedings.neurips.cc/paper/2021/file/23451391cd1399019fa0421129066bc6-Paper.pdf" target="_blank">NeurIPS'21</a>, <a href="https://openreview.net/pdf?id=cZAi1yWpiXQ" target="_blank">ICLR'22</a>, <a href="https://openreview.net/pdf?id=s-pcpETLpY" target="_blank">CLeaR'22</a>, <a href="https://proceedings.mlr.press/v202/yao23a/yao23a.pdf" target="_blank">ICML'23</a>, <a href="https://openreview.net/pdf?id=Q0s6kgrUMr" target="_blank">ICLR'25</a>)</p></li>
<li><p>causal and probabilistic graph model (<a href="https://proceedings.neurips.cc/paper_files/paper/2022/file/08887999616116910fccec17a63584b5-Paper-Conference.pdf" target="_blank">NeurIPS'22</a>, <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Adjustment_and_Alignment_for_Unbiased_Open_Set_Domain_Adaptation_CVPR_2023_paper.pdf" target="_blank">CVPR'23</a>, <a href="https://proceedings.neurips.cc/paper_files/paper/2022/file/987913de7a2963359196d4491d0fd4e7-Paper-Conference.pdf" target="_blank">NeurIPS'23</a>, <a href="https://openreview.net/pdf?id=R1CximX3Cw" target="_blank">NeurIPS'25</a>)</p></li>
</ul>

<ul>
<h3>Weakly Supervised and Self-supervised Representation Learning</h3>
Modern machine learning is migrating to the era of complex models (e.g., deep neural networks), which emphasizes the data representation highly. This learning paradigm is known as representation learning. It is noted that representation learning normally requires a plethora of well-annotated data. Nonetheless, for startups or non-profit organizations, such data is barely acquirable due to the cost of labeling data or the intrinsic scarcity in the given domain. These practical issues motivate us to research and pay attention to weakly supervised representation learning (WSRL), since WSRL does not require such a huge amount of annotated data. Over the years, we have developed techniques for weakly supervised representation learning, such as label-noise representation learning and wildly transferable representation learning. More recently, we are working on self-supervised representation learning.
</ul>

<ul>
Relevant Work/Publications:
</ul>
<ul>
<li><p>machine learning with noisy labels (<a href="https://mitpress.mit.edu/books/series/adaptive-computation-and-machine-learning-series" target="_blank">Monograph</a>, <a href="https://arxiv.org/pdf/2011.04406.pdf" target="_blank">Survey</a>, <a href="https://www.ijcai.org/proceedings/2024/0978.pdf" target="_blank">IJCAI ECS'24</a>)</p></li>
<li><p>training deep networks via sample selection (<a href="https://proceedings.neurips.cc/paper/2018/file/a19744e268754fb0148b017647355b7b-Paper.pdf" target="_blank">NeurIPS'18</a>, <a href="http://proceedings.mlr.press/v97/yu19b/yu19b.pdf" target="_blank">ICML'19</a>, <a href="https://openreview.net/pdf?id=Eql5b1_hTE4" target="_blank">ICLR'21</a>, <a href="https://proceedings.neurips.cc/paper/2021/file/cc7e2b878868cbae992d1fb743995d8f-Paper.pdf" target="_blank">NeurIPS'21</a>, <a href="https://openreview.net/pdf?id=qzM1Tw5i7N" target="_blank">TMLR'22</a>, <a href="https://openreview.net/pdf?id=xENf4QUL4LW" target="_blank">ICLR'22</a>, <a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/d763b4a2dde0ae7b77498516ce9f439e-Paper-Conference.pdf" target="_blank">NeurIPS'23</a>, <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Xia_Combating_Noisy_Labels_with_Sample_Selection_by_Mining_High-Discrepancy_Examples_ICCV_2023_paper.pdf" target="_blank">ICCV'23</a>, <a href="https://arxiv.org/pdf/2403.13241" target="_blank">TPAMI'24</a>, <a href="https://ieeexplore.ieee.org/document/10509799" target="_blank">TPAMI'24</a>, <a href="https://openreview.net/pdf?id=OfIUAlo2hJ" target="_blank">NeurIPS'25</a>)</p></li>
<li><p>estimating the noise transition matrix (<a href="https://proceedings.neurips.cc/paper/2018/file/aee92f16efd522b9326c25cc3237ac15-Paper.pdf" target="_blank">NeurIPS'18</a>, <a href="https://proceedings.neurips.cc/paper/2019/file/9308b0d6e5898366a4a986bc33f3d3e7-Paper.pdf" target="_blank">NeurIPS'19</a>, <a href="https://proceedings.neurips.cc/paper/2020/file/512c5cad6c37edb98ae91c8a76c3a291-Paper.pdf" target="_blank">NeurIPS'20</a>, <a href="http://proceedings.mlr.press/v139/li21l/li21l.pdf" target="_blank">ICML'21</a>, <a href="https://proceedings.mlr.press/v162/yang22p/yang22p.pdf" target="_blank">ICML'22</a>, <a href="https://openreview.net/pdf?id=aFzaXRImWE" target="_blank">ICLR'23</a>, <a href="https://ieeexplore.ieee.org/document/10049697" target="_blank">TPAMI'23</a>)</p></li>
<li><p>designing explicit and implicit regularization (<a href="https://proceedings.mlr.press/v119/han20c/han20c.pdf" target="_blank">ICML'20</a>, <a href="https://proceedings.neurips.cc/paper_files/paper/2022/file/47f75e809409709c6d226ab5ca0c9703-Paper-Conference.pdf" target="_blank">NeurIPS'22</a>)</p></li>
<li><p>instance-dependent label-noise learning (<a href="https://proceedings.neurips.cc/paper/2020/file/5607fe8879e4fd269e88387e8cb30b7e-Paper.pdf" target="_blank">NeurIPS'20</a>, <a href="http://proceedings.mlr.press/v139/berthon21a/berthon21a.pdf" target="_blank">ICML'21</a>, <a href="https://ojs.aaai.org/index.php/AAAI/article/view/17221/17028" target="_blank">AAAI'21</a>, <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Cheng_Instance-Dependent_Label-Noise_Learning_With_Manifold-Regularized_Transition_Matrix_Estimation_CVPR_2022_paper.pdf" target="_blank">CVPR'22</a>, <a href="https://ieeexplore.ieee.org/document/10404058" target="_blank">TPAMI'23</a>, <a href="https://ieeexplore.ieee.org/document/10209198" target="_blank">TPAMI'23</a>, <a href="https://ieeexplore.ieee.org/document/10418893" target="_blank">TPAMI'24</a>, <a href="https://openreview.net/pdf?id=P42DbV2nuV" target="_blank">ICLR'25</a>, <a href="https://openreview.net/pdf?id=d_w12b7fb20" target="_blank">TPAMI'25</a>)</p></li>
<li><p>instance-dependent positive-unlabeled learning (<a href="https://ieeexplore.ieee.org/document/9361303" target="_blank">TPAMI'21</a>, <a href="https://openreview.net/pdf?id=aYAA-XHKyk" target="_blank">ICLR'22</a>, <a href="https://raw.githubusercontent.com/mlresearch/v235/main/assets/wu24ad/wu24ad.pdf" target="_blank">ICML'24</a>)</p></li>
<li><p>class-wise denoising and truncated estimator (<a href="https://ieeexplore.ieee.org/document/9784878" target="_blank">TPAMI'22</a>, <a href="https://ieeexplore.ieee.org/document/10375792" target="_blank">TPAMI'23</a>)</p></li>
<li><p>learning with noisy complex (open-set, multi-label, long-tailed and correspondence) data (<a href="https://ieeexplore.ieee.org/document/9790332" target="_blank">TPAMI'22</a>, <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Xia_Holistic_Label_Correction_for_Noisy_Multi-Label_Classification_ICCV_2023_paper.pdf" target="_blank">ICCV'23</a>, <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Lu_Label-Noise_Learning_with_Intrinsically_Long-Tailed_Data_ICCV_2023_paper.pdf" target="_blank">ICCV'23</a>, <a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Zhao_Mitigating_Noisy_Correspondence_by_Geometrical_Structure_Consistency_Learning_CVPR_2024_paper.pdf" target="_blank">CVPR'24</a>, <a href="https://openreview.net/pdf?id=uocLJOnKBv" target="_blank">ICML'25</a>, <a href="https://openreview.net/pdf?id=jTCiQpV0Lx" target="_blank">NeurIPS'25</a>)</p></li>
<li><p>learning with complementary and partial labels (<a href="http://proceedings.mlr.press/v119/feng20a/feng20a.pdf" target="_blank">ICML'20</a>, <a href="https://proceedings.neurips.cc/paper/2020/file/7bd28f15a49d5e5848d6ec70e584e625-Paper.pdf" target="_blank">NeurIPS'20</a>, <a href="https://openreview.net/pdf?id=qqdXHUGec9h" target="_blank">ICLR'22</a>, <a href="https://link.springer.com/article/10.1007/s10994-023-06434-6" target="_blank">MLJ'23</a>, <a href="https://link.springer.com/article/10.1007/s10994-023-06485-9" target="_blank">MLJ'23</a>)</p></li>
<li><p>learning with weakly supervised labels (<a href="https://www.ijcai.org/proceedings/2020/0361.pdf" target="_blank">IJCAI'20</a>, <a href="http://proceedings.mlr.press/v139/feng21d/feng21d.pdf" target="_blank">ICML'21</a>, <a href="http://proceedings.mlr.press/v139/wu21f/wu21f.pdf" target="_blank">ICML'21</a>, <a href="https://ojs.aaai.org/index.php/AAAI/article/view/17222/17029" target="_blank">AAAI'21</a>, <a href="https://www.jmlr.org/papers/volume23/21-0946/21-0946.pdf" target="_blank">JMLR'22</a>, <a href="https://proceedings.mlr.press/v202/wei23a/wei23a.pdf" target="_blank">ICML'23</a>, <a href="https://papers.nips.cc/paper_files/paper/2024/file/92440ec643f4e9f17409557b6516566e-Paper-Conference.pdf" target="_blank">NeurIPS'24</a>)</p></li>
<li><p>learning from crowds (<a href="https://link.springer.com/article/10.1007/s10994-017-5674-0" target="_blank">MLJ'17</a>, <a href="https://link.springer.com/article/10.1007/s10994-018-5716-2" target="_blank">MLJ'18</a>, <a href="https://link.springer.com/article/10.1007/s10994-018-5766-5" target="_blank">MLJ'18</a>, <a href="https://ieeexplore.ieee.org/document/9765651" target="_blank">TNNLS'22</a>)</p></li>
<li><p>wildly transferable representation learning (<a href="https://arxiv.org/pdf/1905.07720.pdf" target="_blank">arXiv'19</a>, <a href="https://proceedings.neurips.cc/paper/2021/file/af5d5ef24881f3c3049a7b9bfe74d58b-Paper.pdf" target="_blank">NeurIPS'21</a>, <a href="https://openreview.net/pdf?id=MEpKGLsY8f" target="_blank">ICLR'22</a>, <a href="https://link.springer.com/article/10.1007/s11263-024-02012-y" target="_blank">IJCV'24</a>)</p></li>
<li><p>few-shot representation learning (<a href="https://proceedings.mlr.press/v202/dong23d/dong23d.pdf" target="_blank">ICML'23</a>, <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Hard_Sample_Matters_a_Lot_in_Zero-Shot_Quantization_CVPR_2023_paper.pdf" target="_blank">CVPR'23</a>, <a href="https://raw.githubusercontent.com/mlresearch/v235/main/assets/tian24b/tian24b.pdf" target="_blank">ICML'24</a>, <a href="https://papers.nips.cc/paper_files/paper/2024/file/1529a05fdff470f4e7c239c80d85e28e-Paper-Conference.pdf" target="_blank">NeurIPS'24</a>)</p></li>
<li><p>data-efficient representation learning (<a href="https://openreview.net/pdf?id=7D5EECbOaf9" target="_blank">ICLR'23</a>)</p></li>
<li><p>data-free continual learning (<a href="https://openreview.net/pdf?id=3KVHR1b9UZ" target="_blank">ICML'25</a>)</p></li>
<li><p>semi-supervised representation learning (<a href="https://proceedings.neurips.cc/paper/2021/file/e06f967fb0d355592be4e7674fa31d26-Paper.pdf" target="_blank">NeurIPS'21</a>, <a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/088d99765bc121c6df215da7d45bc4e9-Paper-Conference.pdf" target="_blank">NeurIPS'23</a>, <a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/3b11c5cc84b6da2838db348b37dbd1a2-Paper-Conference.pdf" target="_blank">NeurIPS'23</a>, <a href="https://raw.githubusercontent.com/mlresearch/v235/main/assets/li24bv/li24bv.pdf" target="_blank">ICML'24</a>, <a href="https://raw.githubusercontent.com/mlresearch/v235/main/assets/li24bv/li24bv.pdf" target="_blank">IJCAI'25</a>)</p></li>
<li><p>imitation learning with diverse-quality demonstrations (<a href="https://proceedings.mlr.press/v119/tangkaratt20a/tangkaratt20a.pdf" target="_blank">ICML'20</a>, <a href="https://www.jair.org/index.php/jair/article/view/15819/27029" target="_blank">JAIR'24</a>)</p></li>
<li><p>self-supervised representation learning (<a href="https://proceedings.mlr.press/v162/zhou22l/zhou22l.pdf" target="_blank">ICML'22</a>, <a href="https://proceedings.neurips.cc/paper_files/paper/2022/file/850e8063d902e0825d3c5504d183bafe-Paper-Conference.pdf" target="_blank">NeurIPS'22</a>, <a href="https://papers.nips.cc/paper_files/paper/2023/file/40bb79c081828bebdc39d65a82367246-Paper-Conference.pdf" target="_blank">NeurIPS'23</a>, <a href="https://openreview.net/pdf?id=kx2XZlmgB1" target="_blank">ICLR'24</a>)</p></li>
</ul>

<ul>
<h3>Robustness, Security and Privacy in Machine Learning</h3>
In this research thrust, I am interested in the following question: How can we preserve the robustness, security and privacy in training complex models? We have investigated learning algorithms for handling large-scale sensitive data safely. One of the key ideas is to bridge private updates of the primal variable with gradual curriculum learning. We have proposed one of the pioneer approaches for investigating the robustness of residual networks from the perspective of dynamic system. Specifically, we exploited the step factor in the Euler method to control the robustness of ResNet in both its training and generalization. More recently, we derived a series of adversarial learning algorithms, which mainly focus on empirical defense. Meanwhile, we are working on out-of-distribution detection and generalization.
</ul>

<ul>
Relevant Work/Publications:
</ul>
<ul>
<li><p>trustworthy machine learning under imperfect data (<a href="https://link.springer.com/book/10.1007/978-981-96-9396-2" target="_blank">Monograph</a>, <a href="https://www.ijcai.org/proceedings/2024/0978.pdf" target="_blank">IJCAI ECS'24</a>)</p></li>
<li><p>out-of-distribution detection (<a href="https://proceedings.neurips.cc/paper_files/paper/2022/file/63fa7efdd3bcf944a4bd6e0ff6a50041-Paper-Conference.pdf" target="_blank">NeurIPS'22</a>, <a href="https://proceedings.neurips.cc/paper_files/paper/2022/file/f0e91b1314fa5eabf1d7ef6d1561ecec-Paper-Conference.pdf" target="_blank">NeurIPS'22</a>, <a href="https://proceedings.mlr.press/v202/jiang23e/jiang23e.pdf" target="_blank">ICML'23</a>, <a href="https://proceedings.mlr.press/v202/zhu23g/zhu23g.pdf" target="_blank">ICML'23</a>, <a href="https://openreview.net/pdf?id=hdghx6wbGuD" target="_blank">ICLR'23</a>, <a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/e812af67a942c21dd0104bd929f99da1-Paper-Conference.pdf" target="_blank">NeurIPS'23</a>, <a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/46d943bc6a15a57c923829efc0db7c7a-Paper-Conference.pdf" target="_blank">NeurIPS'23</a>, <a href="https://papers.nips.cc/paper_files/paper/2023/file/e43f900f571de6c96a70d5724a0fb565-Paper-Conference.pdf" target="_blank">NeurIPS'23</a>, <a href="https://papers.nips.cc/paper_files/paper/2024/file/25cc3adf8c85f7c70989cb8a97a691a7-Paper-Conference.pdf" target="_blank">NeurIPS'24</a>, <a href="https://jmlr.org/papers/volume25/23-1257/23-1257.pdf" target="_blank">JMLR'24</a>, <a href="https://www.computer.org/csdl/journal/tp/5555/01/10844561/23zUi92f3os" target="_blank">TPAMI'25</a>)</p></li>
<li><p>out-of-distribution generalization (<a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/d73d5645ddbb9ada6c862116435574f6-Paper-Conference.pdf" target="_blank">NeurIPS'23</a>, <a href="https://openreview.net/pdf?id=esFxSb_0pSL" target="_blank">ICLR'23</a>, <a href="https://openreview.net/pdf/ead13866b1d8951f087779370b079c54800f219e.pdf" target="_blank">ICLR'23</a>, <a href="https://link.springer.com/article/10.1007/s11263-024-02075-x" target="_blank">IJCV'24</a>, <a href="https://openreview.net/pdf?id=pekYL20W3n" target="_blank">ICML'25</a>)</p></li>
<li><p>out-of-model generalization (<a href="https://openreview.net/pdf?id=LuVulfPgZN" target="_blank">ICLR'25</a>)</p></li>
<li><p>domain generalization and test-time adaptation (<a href="https://proceedings.mlr.press/v202/dai23d/dai23d.pdf" target="_blank">ICML'23</a>, <a href="https://papers.nips.cc/paper_files/paper/2023/file/893ca2e5ff5bb258da30e0a82f4c8de9-Paper-Conference.pdf" target="_blank">NeurIPS'23</a>, <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Huang_Robust_Generalization_Against_Photon-Limited_Corruptions_via_Worst-Case_Sharpness_Minimization_CVPR_2023_paper.pdf" target="_blank">CVPR'23</a>, <a href="https://arxiv.org/pdf/2401.08464" target="_blank">AAAI'24</a>)</p></li>
<li><p>exploring diverse-structured networks for robustness (<a href="https://www.ijcai.org/proceedings/2019/0595.pdf" target="_blank">IJCAI'19</a>, <a href="http://proceedings.mlr.press/v139/du21f/du21f.pdf" target="_blank">ICML'21</a>, <a href="https://raw.githubusercontent.com/mlresearch/v235/main/assets/lin24v/lin24v.pdf" target="_blank">ICML'24</a>)</p></li>
<li><p>geometry-aware adversarial training and robust overfitting (<a href="https://proceedings.mlr.press/v119/zhang20z/zhang20z.pdf" target="_blank">ICML'20</a>, <a href="https://openreview.net/pdf?id=iAX0l6Cz8ub" target="_blank">ICLR'21</a>, <a href="https://proceedings.neurips.cc/paper/2021/file/c3a690be93aa602ee2dc0ccab5b7b67e-Paper.pdf" target="_blank">NeurIPS'21</a>, <a href="https://proceedings.mlr.press/v162/zhou22k/zhou22k.pdf" target="_blank">ICML'22</a>, <a href="https://proceedings.mlr.press/v162/yu22b/yu22b.pdf" target="_blank">ICML'22</a>, <a href="https://www.ijcai.org/proceedings/2022/0512.pdf" target="_blank">IJCAI'22</a>, <a href="https://openreview.net/pdf?id=2V1Z0Jdmss" target="_blank">ICLR'24</a>)</p></li>
<li><p>detecting adversarial data via maximum mean discrepancy (<a href="http://proceedings.mlr.press/v139/gao21b/gao21b.pdf" target="_blank">ICML'21</a>, <a href="https://proceedings.mlr.press/v202/zhang23ac/zhang23ac.pdf" target="_blank">ICML'23</a>)</p></li>
<li><p>fast and reliable evaluation of adversarial robustness (<a href="https://proceedings.mlr.press/v162/gao22i/gao22i.pdf" target="_blank">ICML'22</a>)</p></li>
<li><p>improving adversarial robustness via invariant features, mutual information and collaboration (<a href="http://proceedings.mlr.press/v139/zhou21e/zhou21e.pdf" target="_blank">ICML'21</a>, <a href="https://proceedings.mlr.press/v162/zhou22j/zhou22j.pdf" target="_blank">ICML'22</a>, <a href="https://proceedings.neurips.cc/paper_files/paper/2022/file/d16152d53088ad779ffa634e7bf66166-Paper-Conference.pdf" target="_blank">NeurIPS'22</a>)</p></li>
<li><p>adversarial training with weakly supervised labels (<a href="https://arxiv.org/pdf/2102.03482.pdf" target="_blank">arXiv'21</a>, <a href="https://openreview.net/pdf?id=zlQXV7xtZs" target="_blank">TMLR'22</a>, <a href="https://proceedings.neurips.cc/paper_files/paper/2022/file/959f70ee50044bed305e48e3484005a7-Paper-Conference.pdf" target="_blank">NeurIPS'22</a>, <a href="https://openreview.net/pdf?id=u6TRGdzhfip" target="_blank">ICLR'22</a>)</p></li>
<li><p>model-inversion, black-box and poisoning attacks (<a href="https://arxiv.org/pdf/2411.10023" target="_blank">Survey</a>, <a href="https://dl.acm.org/doi/pdf/10.1145/3534678.3539376" target="_blank">KDD'22</a>, <a href="https://papers.nips.cc/paper_files/paper/2022/file/7a9745f251508a053425a256490b0665-Paper-Conference.pdf" target="_blank">NeurIPS'22</a>, <a href="https://proceedings.mlr.press/v202/zhu23d/zhu23d.pdf" target="_blank">ICML'23</a>, <a href="https://papers.nips.cc/paper_files/paper/2024/file/3a797b10ff20562b1ecee0d4e914c1c7-Paper-Conference.pdf" target="_blank">NeurIPS'24</a>, <a href="https://openreview.net/pdf?id=Z6b7xavA3Y" target="_blank">NeurIPS'25</a>, <a href="https://www.computer.org/csdl/journal/tp/5555/01/10949821/25DZs7NRDm8" target="_blank">TPAMI'25</a>)</p></li>
<li><p>privacy-preserving stochastic learning and optimization (<a href="https://ieeexplore.ieee.org/document/8949708" target="_blank">TKDE'19</a>, <a href="https://arxiv.org/pdf/2206.13011" target="_blank">MLJ'24</a>)
</p></li>
<li><p>robust tensor learning with nonconvex regularization (<a href="https://proceedings.mlr.press/v97/yao19a/yao19a.pdf" target="_blank">ICML'19</a>, <a href="https://www.jmlr.org/papers/volume23/20-1368/20-1368.pdf" target="_blank">JMLR'22</a>)</p></li>
<li><p>few-shot adversarial prompt learning (<a href="https://papers.nips.cc/paper_files/paper/2024/file/05aedcaf4bc6e78a5e22b4cf9114c5e8-Paper-Conference.pdf" target="_blank">NeurIPS'24</a>)</p></li>
</ul>

<ul>
<h3>Federated, Efficient and Graph Machine Learning</h3>
Motivated by the success of federated learning (FL), we are exploring to leverage the power of FL for addressing the data privacy and governance issues, meanwhile maintains the model robustness to noisy labels and adversarial attacks. Besides, in industrial-level FL environments, we are the first to study the collaboration between the device and the cloud, namely the device-cloud collaborative learning (DCCL) framework. Motivated by the success of efficient machine learning, we are exploring to leverage the power of automated machine learning (AutoML) for addressing the domain problems in trustworthy learning, such as searching the small-loss percentage under noisy labels or robust network structures under adversarial examples. In high level, we have formulated the synertistic interaction between trustworthy learning and automated learning as a bi-level programming. Specifically, we designed a domain-specific search space based on domain knowledge in trustworthy learning. Meanwhile, we proposed a novel Newton algorithm to solve the bi-level optimization problem efficiently. More recently, we are working on trustworthy graph neural networks and knowledge graphs.
</ul>

<ul>
Relevant Work/Publications:
</ul>
<ul>
<li><p>trustworthy federated learning from data perspective (<a href="https://proceedings.mlr.press/v162/tang22d/tang22d.pdf" target="_blank">ICML'22</a>, <a href="https://openreview.net/pdf?id=phnGilhPH8" target="_blank">NeurIPS'23</a>, <a href="https://openreview.net/pdf?id=wwmKVO8bsR" target="_blank">NeurIPS'23</a>, <a href="https://openreview.net/pdf?id=qxLVaYbsSI" target="_blank">ICLR'24</a>, <a href="https://openreview.net/pdf?id=tm8s3696Ox" target="_blank">ICLR'24</a>, <a href="https://papers.nips.cc/paper_files/paper/2024/file/31e6e0c09325a3be16d93f84e40e0c7e-Paper-Conference.pdf" target="_blank">NeurIPS'24</a>, <a href="https://openreview.net/pdf?id=jM4ULVYF66" target="_blank">NeurIPS'25</a>)</p></li>
<li><p>trustworthy federated learning from client perspective (<a href="https://openreview.net/pdf?id=eKllxpLOOm" target="_blank">ICLR'23</a>, <a href="https://arxiv.org/pdf/2106.13239.pdf" target="_blank">TNNLS'23</a>, <a href="https://openreview.net/pdf?id=giU9fYGTND" target="_blank">ICLR'24</a>, <a href="https://openreview.net/pdf?id=ShQrnAsbPI" target="_blank">ICLR'24</a>, <a href="https://arxiv.org/pdf/2312.12703.pdf" target="_blank">AAAI'24</a>, <a href="https://openreview.net/pdf?id=dVMESwnMlo" target="_blank">TMLR'25</a>)</p></li>
<li><p>trustworthy federated learning from server perspective (<a href="https://dl.acm.org/doi/pdf/10.1145/3604939" target="_blank">TKDD'23</a>, <a href="https://raw.githubusercontent.com/mlresearch/v235/main/assets/yan24a/yan24a.pdf" target="_blank">ICML'24</a>, <a href="https://openreview.net/pdf?id=B8akWa62Da" target="_blank">ICLR'25</a>)</p></li>
<li><p>efficient federated learning (<a href="https://arxiv.org/pdf/2502.09104" target="_blank">IJCAI'25</a>)</p></li>
<li><p>device-cloud collaborative learning (<a href="https://dl.acm.org/doi/abs/10.1145/3447548.3467097" target="_blank">KDD'21</a>, <a href="https://dl.acm.org/doi/pdf/10.1145/3534678.3539181" target="_blank">KDD'22</a>)</p></li>
<li><p>robust neural architecture search (<a href="https://proceedings.mlr.press/v119/yao20b/yao20b.pdf" target="_blank">ICML'20</a>, <a href="https://ieeexplore.ieee.org/document/10509799" target="_blank">TPAMI'24</a>)</p></li>
<li><p>efficient neural architecture search (<a href="https://arxiv.org/pdf/2111.15097.pdf" target="_blank">ECCV'22</a>, <a href="https://arxiv.org/pdf/2211.12759" target="_blank">AAAI'23</a>)</p></li>
<li><p>robust graph neural networks (<a href="https://openreview.net/pdf?id=wkMG8cdvh7-" target="_blank">ICLR'22</a>, <a href="https://proceedings.mlr.press/v202/zhou23s/zhou23s.pdf" target="_blank">ICML'23</a>, <a href="https://openreview.net/pdf?id=r7imkFEAQb" target="_blank">TMLR'23</a>, <a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/435986a8cc3e0667648df5d1c2d55c83-Paper-Conference.pdf" target="_blank">NeurIPS'23</a>, <a href="https://raw.githubusercontent.com/mlresearch/v235/main/assets/wu24ae/wu24ae.pdf" target="_blank">ICML'24</a>)</p></li>
<li><p>interpretable and invariant graph neural networks (<a href="https://proceedings.neurips.cc/paper_files/paper/2022/file/72d9a23e3895b5670e650c2e742065c9-Paper-Conference.pdf" target="_blank">NeurIPS'22</a>, <a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/e21a7b668ce3ea2c9c964c52d1c9f161-Supplemental-Conference.pdf" target="_blank">NeurIPS'23</a>, <a href="https://dl.acm.org/doi/10.1145/3544977" target="_blank">TKDD'23</a>, <a href="https://raw.githubusercontent.com/mlresearch/v235/main/assets/chen24b/chen24b.pdf" target="_blank">ICML'24</a>)</p></li>
<li><p>knowledge graph reasoning (<a href="https://dl.acm.org/doi/pdf/10.1145/3580305.3599404" target="_blank">KDD'23</a>, <a href="https://arxiv.org/pdf/2403.10231" target="_blank">ICLR'24</a>)</p></li>
</ul>

<ul>
<h3>Interdisciplinary Problems: Healthcare Analytics and AI for Science</h3>
Unlabeled data and data with noisy labels are commonly encountered in medical image analysis. To tackle these two intractable problems, this proposed project will use machine learning (ML) technologies to develop robust, efficient and automated diagnosis algorithms, which can be applied to identify diverse diseases. We will verify our proposed methods on a series of public datasets, such as MICCAI BraTS, MICCAI iSeg2019, ChestX-ray14 and ISBI CHAOS. The aim of this project is to reduce the demands of annotated medical data, decrease the costs of manual screening, and prompt the development of smart healthcare. We hope that our designed model can provide reasonable medical interpretation for doctors, helping them better understand the functioning mechanism of intelligent medical diagnosis. More recently, we are working on the synergy between machine learning and science (e.g., drug and materials discovery).
</ul>

<ul>
Relevant Work/Publications:
</ul>
<ul>
<li><p>learning causally invariant representations on graphs with application to drug discovery (<a href="https://proceedings.neurips.cc/paper_files/paper/2022/file/8b21a7ea42cbcd1c29a7a88c444cce45-Supplemental-Conference.pdf" target="_blank">NeurIPS'22</a>)
</p></li>
<li><p>robust representation learning for computer-aided diagnosis (<a href="https://openreview.net/pdf?id=5II12ypVQo" target="_blank">TMLR'23</a>)</p></li>
<li><p>plantorganelle hunter for plant organelle phenotyping in electron microscopy (<a href="https://www.nature.com/articles/s41477-023-01527-5" target="_blank">Nature Plants'23</a>)</p></li>
<li><p>invariant representation of subsets with application to drug discovery (<a href="https://openreview.net/pdf?id=eepoE7iLpL" target="_blank">ICLR'24</a>)</p></li>
<li><p>propagating long-range interaction in molecular graphs (<a href="https://openreview.net/pdf?id=CUfSCwcgqm" target="_blank">ICLR'24</a>)</p></li>
<li><p>fast and accurate blind flexible docking (<a href="https://openreview.net/pdf?id=iezDdA9oeB" target="_blank">ICLR'25</a>)</p></li>
<li><p>molecule-and-text cross-modal representation learning (<a href="https://openreview.net/pdf?id=mun3bGqdDM" target="_blank">ICLR'25</a>)</p></li>
</ul>

</div>

   <div>
    <h2><hr><a name="sponsors"></a>Sponsors, Research Impact and Industry Impact</h2>
	<ul>For transparency and acknowledgement, TMLR group is/was gratefully supported by RGC and UGC of Hong Kong (Awards YCRG-C2005-24Y, GRF-12200725, ECS-22200720, RMGS), NSFC (Awards GP-62376235, YSF-62006202), GDST (Awards BRF-2024A1515012399, BRF-2022A1515011652), RIKEN AIP (Awards CRF, BAIHO), HKBU Research (Awards RC-FNRA-IG/22-23/SCI/04, RC-PRSF-2425-SCI-01, RCIA, Talent100PSS, TRSS, Tier1SG, TSA), HKBU SCI (Award FRIS), HKBU CSD (Awards CSDIS, CSDSG), and <a href="https://en.wikipedia.org/wiki/Big_Tech" target="_blank">industry research labs</a> (Microsoft, Google, NVIDIA, ByteDance, Baidu, Alibaba, Tencent, ZhipuAI, TCL, WholeLink). For research impact, due to great collaborators and students, our trustworthy ML research has won <a href="https://blog.neurips.cc/2022/11/21/announcing-the-neurips-2022-awards/" target="_blank">Outstanding Paper Award</a> at NeurIPS'22, <a href="https://www.paperdigest.org/2022/05/most-influential-nips-papers-2022-05/" target="_blank">Most Influential Paper</a> at NeurIPS'18, and <a href="https://federated-learning.org/fl@fm-neurips-2024/FL@FM-NeurIPS24StudentAward1.png" target="_blank">Outstanding Student Paper Award</a> at NeurIPS'24 Workshop. For industry impact, our trustworthy ML research has influenced and landed in many industry products, such as <a href="https://mp.weixin.qq.com/s/0GypXaICRLrJFywLpdW8bA" target="_blank">Alibaba Advertisement</a>, Alibaba Taobao, Alibaba Alipay, ByteDance Seed, Baidu PaddlePaddle, Tencent WeChat, Tencent iDrug, and TCL CSOT.</ul>
   </div>

</td>
</tr>
</table>
</body>
</html>
