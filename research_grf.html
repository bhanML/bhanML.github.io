<html>

<head>
    <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
    <link rel="stylesheet" type="text/css" href="style.css" />
    <title>Bo Han</title>
    <base href="https://bhanML.github.io/research.html">
</head>

<body>
<h1 style="padding-left: 0.5em">Bo Han</h1><hr>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
    <div class="menu-item"><a href="index.html">Home</a></div>
	<div class="menu-item"><a href="news.html">News</a></div>
    <div class="menu-item"><a href="research.html">Research</a></div>
	<div class="menu-item"><a href="group.html">Research Group</a></div>
	<div class="menu-item"><a href="service.html">Professional Service</a></div>
    <div class="menu-item"><a href="teaching.html">Teaching</a></div>
    <div class="menu-item"><a href="codedata.html">Codes & Data</a></div>
	<div class="menu-item"><a href="awards.html">Awards & Honors</a></div>
</td>
<td id="layout-content">

<div>
        <h2><a name="research_ecs"></a>RGC General Research Fund</h2> (PI: Prof. Bo Han, Department of Computer Science, Hong Kong Baptist University)<br><br>

<ul>
<h3>Project Award Information</h3>
<li><p>Award Number: <a href="https://cerg1.ugc.edu.hk/cergprod/scrrm00542.jsp?proj_id=12200725&old_proj_id=null&proj_title=&isname=&ioname=&institution=HKBU&subject=&pages=1&year=2025&theSubmit=12200725" target="_blank">RGC GRF 12200725</a></p></li>
<li><p>Title: Towards Dynamic Knowledge-aware Federated Learning for Foundation Models</p></li>
<li><p>Principal Investigator (PI): Prof. Bo Han, Department of Computer Science, Hong Kong Baptist University</p></li>
</ul>

<ul>
<h3>Project Summary</h3>
Foundation Models (FMs) have become pivotal in advancing artificial intelligence, offering a flexible framework for developing various industry sectors. Take an example of healthcare, which costs HK$243.2 billion (8.5% of GDP) for Hong Kong in 2021-22, applying FMs can improve the efficiency of healthcare systems, e.g., providing informative assistance on analyzing patient records. However, training FMs usually
relies on using a central server to aggregate massive amounts of data, thus increasing the risk of privacy leakage and data monopolization. In this context, Federated Learning (FL) emerges as a promising approach that can collaboratively train FMs, and embody privacy protection by enabling clients to contribute to FMs training without sending their data. Recent advancements, e.g., TogetherAI, have shown promising outcomes in this field. However, direct applications of existing FL framework to train FMs are impeded due to below challenges: How to align dynamic data requirements of FMs with static data assumptions of FL? FMs necessitate continuous updates, e.g., clients often receive fresh data to keep knowledge of the model. However, existing FL paradigms neglect the challenge of aligning dynamic data requirements of FMs with static data assumptions of FL. How to deal with the data leakage when pre-training FMs in an FL manner? FL fundamentally relies on gradient exchange. However, exchanged gradients can be exploited by adversaries to infer sensitive information, leading to the risk of data leakage. How to deal with imperfect data when fine-tuning FMs in an FL scheme? Data quality plays a crucial role in fine-tuning FMs. However, the data collected by clients may be noisy or even maliciously altered, posing threats to FM performance. In summary, in this project, we aim to develop a new FL paradigm for FMs in dynamic knowledge environments, which can be further deployed to broader scientific and industrial applications.
</ul>

<ul>
<h3>Research Publications</h3>
The following papers focus on federated foundation model learning:
</ul>
<ul>
<li><p>TBD</p></li>
</ul>

<ul> The following papers focus on federated foundation model pre-training:
</ul>
<ul>
<li><p>TBD</p></li>
</ul>

<ul> The following papers focus on federated foundation model fine-tuning:
</ul>
<ul>
<li><p>TBD</p></li>
</ul>

<ul>
<h3>Software</h3>
<li><p>TBD, [code]</p></li>
</ul>

<ul>
<h3>Education</h3>
<li><p>UG Course: TBD</p></li>
<li><p>PG Course: TBD</p></li>
<li><p>Tutorial: TBD</p></li>
<li><p>Undergraduate Research Programme (<a href="https://research.hkbu.edu.hk/study-with-us/undergraduate-research-programme" target="_blank">UGRP</a>): TBD</p></li>
<li><p>Summer Undergraduate Research Fellowship: TBD</p></li>
</ul>

<ul>
<h3>Collaborators</h3>
<li><p> University: TBD</p></li>
<li><p> Institute: TBD</p></li>
<li><p>	Industry: TBD</p></li>
</ul>

<ul>
<h3>Acknowlewdgement</h3>
This material is based upon work supported by the RGC under Grant No. 12200725. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the RGC.
</ul>

</div>

</td>
</tr>
</table>
</body>
</html>
