<html>

<head>
    <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
    <link rel="stylesheet" type="text/css" href="style.css" />
    <title>Bo Han</title>
    <base href="https://bhanML.github.io/research.html">
</head>

<body>
<h1 style="padding-left: 0.5em">Bo Han</h1><hr>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
    <div class="menu-item"><a href="index.html">Home</a></div>
	<div class="menu-item"><a href="news.html">News</a></div>
    <div class="menu-item"><a href="research.html">Research</a></div>
	<div class="menu-item"><a href="group.html">Research Group</a></div>
	<div class="menu-item"><a href="service.html">Professional Service</a></div>
    <div class="menu-item"><a href="teaching.html">Teaching</a></div>
    <div class="menu-item"><a href="codedata.html">Codes & Data</a></div>
	<div class="menu-item"><a href="awards.html">Awards & Honors</a></div>
</td>
<td id="layout-content">

<div>
        <h2><a name="research_ecs"></a>GDST Basic Research Fund</h2> (PI: Dr. Bo Han, Department of Computer Science, Hong Kong Baptist University)<br><br>

<ul>
<h3>Project Award Information</h3>
<li><p>Award Number: <a href="https://gdstc.gd.gov.cn/zwgk_n/tzgg/content/post_3321216.html" target="_blank">GDST BRF 2022A1515011652</a></p></li>
<li><p>Title: Trustworthy Deep Reasoning with Human-level Constraints</p></li>
<li><p>Principal Investigator (PI): Dr. Bo Han, Department of Computer Science, Hong Kong Baptist University</p></li>
</ul>

<ul>
<h3>Project Summary</h3>
The success of deep learning is mainly due to large-scale high-quality data, such as ImageNet and SQuAD datasets. In practice, these datasets cannot be easily acquired. For example, in computer-aided diagnosis domain, medical images tend to be small-scale and low-quality, which in turn limits the development of deep learning. This urges us to rethink the bottleneck factors of deep learning: data quantity and quality. Namely, how does deep learning handle small-scale low-quality data well? Existing works in robust deep learning (RDL) can partially address this issue (i.e., low-quality data). Specifically, RDL tends to be data-driven and unconscious, which belongs to system-1 deep learning. Given large-scale data, RDL can display the robust perception mechanically to a certain degree. However, when small-scale data, RDL is still far from human-level AI. The exploration of RDL is suitable for an initial research but too restrictive for a lot of real-world applications (e.g., medical imaging analysis). To address the above issues simultaneously, we need system-2 deep learning, which is data-saving and conscious. This proposal aims to echo system-2 deep learning preliminarily, which provides a solution to small-scale low-quality data. In high level, our system-2 intelligent system should behave more human-like: trustworthy perception and logical reasoning. To unify two aspects, we propose a trustworthy deep reasoning (TDR) framework, where human-level constraints (e.g., logic or casality) are embedded into trustworthy learning procedure. The benefit of such embedding is to reduce the estimation error caused by small-scale data. The goal of this project is to develop models, algorithms and prototype system for trustworthy deep reasoning from small-scale low-quality (i.e., noisy) data and deploy the system in real-world field.
</ul>

<ul>
<h3>Research Publications</h3>
<li><p>label-noise learning through the lens of causality (<a href="https://proceedings.mlr.press/v202/yao23a/yao23a.pdf" target="_blank">ICML'23</a>)</p></li>
<li><p>graph neural network based knowledge graph reasoning (<a href="https://dl.acm.org/doi/pdf/10.1145/3580305.3599404" target="_blank">KDD'23</a>)</p></li>
<li><p>robust LLMs reasoning in chain-of-thought prompting with noisy rationales (<a href="https://openreview.net/pdf?id=FbuODM02ra" target="_blank">NeurIPS'24</a>)</p></li>
<li><p>discovery of the hidden world with large language models (<a href="https://openreview.net/pdf?id=w50ICQC6QJ" target="_blank">NeurIPS'24</a>)</p></li>
<li><p>unveiling causal reasoning in large language models (<a href="https://openreview.net/pdf?id=1IU3P8VDbn" target="_blank">NeurIPS'24</a>)</p></li>
<li><p>one-shot subgraph reasoning on large-scale knowledge graphs (<a href="https://openreview.net/pdf?id=QHROe7Mfcb" target="_blank">ICLR'24</a>)</p></li>
<li><p>active reasoning benchmark (<a href="https://openreview.net/pdf?id=LCaTpVuvpj" target="_blank">ICML'25</a>)</p></li>
<li><p>multi-agent reasoning through incomplete information and consensus (<a href="https://openreview.net/pdf?id=RQwexjUCxm" target="_blank">ICML'25</a>)</p></li>
<li><p>a robust method to discover causal or anticausal relation (<a href="https://openreview.net/pdf?id=Q0s6kgrUMr" target="_blank">ICLR'25</a>)</p></li>
<li><p>eliciting causal abilities in large language models for reasoning tasks (<a href="https://arxiv.org/pdf/2412.15314" target="_blank">AAAI'25</a>)</p></li>
</ul>

<ul>
<h3>Software</h3>
<li><p>label-noise learning through the lens of causality, [code]</p></li>
<li><p>graph neural network based knowledge graph reasoning, [<a href="https://github.com/LARS-research/AdaProp" target="_blank">code</a>]</p></li>
<li><p>robust LLMs reasoning in chain-of-thought prompting with noisy rationales, [<a href="https://github.com/tmlr-group/NoisyRationales" target="_blank">code</a>]</p></li>
<li><p>discovery of the hidden world with large language models, [<a href="https://github.com/tmlr-group/CausalCOAT" target="_blank">code</a>]</p></li>
<li><p>unveiling causal reasoning in large language models, [<a href="https://github.com/Haoang97/CausalProbe-2024" target="_blank">code</a>]</p></li>
<li><p>one-shot subgraph reasoning on large-scale knowledge graphs, [<a href="https://github.com/tmlr-group/one-shot-subgraph" target="_blank">code</a>]</p></li>
<li><p>active reasoning benchmark, [<a href="https://github.com/tmlr-group/AR-Bench" target="_blank">code</a>]</p></li>
<li><p>multi-agent reasoning through incomplete information and consensus, [code]</p></li>
<li><p>a robust method to discover causal or anticausal relation, [code]</p></li>
<li><p>eliciting causal abilities in large language models for reasoning tasks, [<a href="https://github.com/tmlr-group/SCIE" target="_blank">code</a>]</p></li>
</ul>

<ul>
<h3>Collaborators</h3>
<li><p> University: Stanford University, Carnegie Mellon University, The University of Sydney, The University of Melbourne, The University of Tokyo, MBZUAI, Hong Kong University of Science and Technology, The Chinese University of Hong Kong, Tsinghua University, Shanghai Jiao Tong University, Fudan University, Wuhan University</p></li>
<li><p>	Industry: JD Explore Academy </p></li>
</ul>

<ul>
<h3>Acknowlewdgement</h3>
This material is based upon work supported by the GDST under Grant No. 2022A1515011652. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the GDST.
</ul>

</div>

</td>
</tr>
</table>
</body>
</html>
